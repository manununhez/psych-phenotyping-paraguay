# Psych Phenotyping Paraguay

**Sistema h√≠brido de NLP para detecci√≥n de ansiedad y depresi√≥n en notas cl√≠nicas**, 
adaptando el proyecto [Spanish Psych Phenotyping](https://github.com/clarafrydman/Spanish_Psych_Phenotyping) 
al contexto ling√º√≠stico y cl√≠nico de Paraguay.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

---

## üöÄ Inicio R√°pido

### Resultados Principales (Cross-Validation 5-Fold, Patient-Level)

| Modelo | F1 Macro (CV) | IC95% | CV% | Mejora vs Baseline |
|--------|---------------|-------|-----|--------------------|
| **TF-IDF char(3,5)** | **0.850 ¬± 0.031** | [0.789, 0.910] | 3.6% | **+73.2%** ‚úÖ |
| **BETO (fine-tuned)** | **0.821 ¬± 0.035** | [0.753, 0.890] | 4.3% | **+67.4%** ‚úÖ |
| **Rule-Based (COL)** | **0.511 ¬± 0.053** | [0.407, 0.615] | 10.4% | +4.1% ‚ö†Ô∏è |
| Dummy Stratified | 0.491 ¬± 0.006 | [0.478, 0.503] | 1.3% | - |
| Dummy Majority | 0.413 ¬± 0.011 | [0.391, 0.435] | 2.8% | - |

**Evaluaciones adicionales (single dev, 641 casos):**
- TF-IDF: 0.866 | BETO: 0.841 | Rule-Based: 0.527
- Todos los modelos caen dentro del IC95% de CV ‚Üí split representativo ‚úÖ

**üéØ Hallazgos clave metodol√≥gicos:**

1. **Cross-Validation 5-fold es la m√©trica principal:**
   - Con 90 pacientes, CV 5-fold usa TODOS los datos ‚Üí estimaci√≥n robusta
   - Varianza real: TF-IDF ¬±3.6%, BETO ¬±4.3% (baja, modelos estables)
   - IC95% cuantifica incertidumbre real del modelo

2. **Consistencia dev vs CV confirma split representativo:**
   - TF-IDF: Dev=0.866 dentro de IC95%=[0.789, 0.910] ‚úÖ
   - BETO: Dev=0.841 dentro de IC95%=[0.753, 0.890] ‚úÖ
   - Rule-Based: Dev=0.527 dentro de IC95%=[0.407, 0.615] ‚úÖ
   - No hubo "lucky split" - split es representativo de la poblaci√≥n

3. **TF-IDF y BETO superan significativamente baseline (p<0.05):**
   - TF-IDF: +73% vs Dummy Stratified (IC95% NO solapan)
   - BETO: +67% vs Dummy Stratified (IC95% NO solapan)
   - Rule-Based: +4% vs baseline (NO significativo, IC95% S√ç solapan)

4. **Gap vocabulario Paraguay vs Colombia:**
   - Rule-Based (patrones colombianos): F1=0.511, CV%=10.4% (inestable)
   - TF-IDF (aprende de datos locales): F1=0.850, CV%=3.6% (estable)
   - **66% de mejora** adaptando al contexto paraguayo

**Estrategia de evaluaci√≥n:**
- **Cross-Validation 5-fold:** M√©trica PRINCIPAL para paper/tesis
  - Usa train+dev (2,490 casos, 72 pacientes) ‚Üí maximiza uso de datos
  - Patient-level stratified, seed 42 (reproducible)
  - IC95% bootstrapped (10,000 iteraciones) para significancia estad√≠stica
- **Single dev evaluation:** Contexto adicional (consistencia con CV)
- **Test set hold-out:** Reservado para evaluaci√≥n final ciega (637 casos, 18 pacientes)
- **Zero leakage:** Split patient-level 60/20/20, 0% overlap verificado

---

## üìö Documentaci√≥n Organizada

### üìÅ docs/01_PROYECTO/ - An√°lisis y Resultados
- **[README_PROYECTO.md](docs/01_PROYECTO/README_PROYECTO.md)** ‚≠ê Documento principal consolidado
  - Contexto del proyecto y dataset
  - Resultados de 3 baselines + an√°lisis de errores
  - Gap vocabulario Paraguay vs Colombia (75% Ansiedad)
  - S√≠ntomas faltantes CIE-10/DSM-5
  - Recomendaciones y pr√≥ximos pasos

- **[METODOLOGIA_VALIDACION.md](docs/01_PROYECTO/METODOLOGIA_VALIDACION.md)** - Split patient-level 60/20/20 y control de leakage

- **[RESUMEN_TESIS.md](docs/01_PROYECTO/RESUMEN_TESIS.md)** - Resumen ejecutivo para defensa

### üìÅ docs/02_CONCEPT_PY/ - Vocabulario Paraguayo
- **[ANALISIS_CONCEPT_PY.md](docs/02_CONCEPT_PY/ANALISIS_CONCEPT_PY.md)** - Propuesta desarrollo vocabulario paraguayo
  - An√°lisis 136 FN Ansiedad
  - Top 50 t√©rminos paraguayos propuestos
  - Plan de mejora F1 0.503 ‚Üí 0.60

- **[ROADMAP_CONCEPT_PY.md](docs/02_CONCEPT_PY/ROADMAP_CONCEPT_PY.md)** - Plan operativo 3 semanas

- **[EVALUACION_PROYECTO_COLOMBIANO.md](docs/02_CONCEPT_PY/EVALUACION_PROYECTO_COLOMBIANO.md)** - An√°lisis t√©cnico fork base

- **[FENOTIPOS_ANSIEDAD_DEPRESION.md](docs/02_CONCEPT_PY/FENOTIPOS_ANSIEDAD_DEPRESION.md)** - Lista exhaustiva 48 fenotipos CIE-10

- **[RESUMEN_CLASIFICACION.md](docs/02_CONCEPT_PY/RESUMEN_CLASIFICACION.md)** - Uso de patrones unificados

### üìÅ docs/03_VALIDACION_PSIQUIATRAS/ - Validaci√≥n Cl√≠nica
- **[GUIA_REUNION_COMPLETA.md](docs/03_VALIDACION_PSIQUIATRAS/GUIA_REUNION_COMPLETA.md)** ‚≠ê Gu√≠a para reuni√≥n con psiquiatras
  - Metodolog√≠a validaci√≥n 25 casos
  - Hallazgos vocabulario paraguayo (6 t√©rminos GAD-7)
  - Template invitaci√≥n profesionales
  - Material: `data/VALIDACION_PSIQUIATRAS_25_CASOS_EXTENDIDO.xlsx` (7 hojas)

### üìÅ docs/04_TECNICO/ - Gu√≠as T√©cnicas
- **[GUIA_MODELOS_CONCEPTUAL.md](docs/04_TECNICO/GUIA_MODELOS_CONCEPTUAL.md)** - Explicaci√≥n detallada TF-IDF, BETO, Rule-Based

- **[COMPARACION_LIMPIEZA.md](docs/04_TECNICO/COMPARACION_LIMPIEZA.md)** - Impacto limpieza duplicados (40.3% reducci√≥n)

- **[EJEMPLO_USO_CLASIFICACION.md](docs/04_TECNICO/EJEMPLO_USO_CLASIFICACION.md)** - Tutorial c√≥digo clasificaci√≥n

### üìú Documentos Hist√≥ricos
- **[docs/historico/](docs/historico/)** - Reportes y planes archivados (oct-nov 2025)
  - Ver [docs/historico/README.md](docs/historico/README.md) para detalles

---

## Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Documentaci√≥n Organizada](#-documentaci√≥n-organizada)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Flujo de Trabajo](#-flujo-de-trabajo)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso R√°pido](#-uso-r√°pido)
- [Baselines Implementados](#-baselines-implementados)
- [Resultados](#-resultados)
- [Decisiones de Dise√±o](#-decisiones-de-dise√±o)
- [Contribuir](#-contribuir)

---

## Descripci√≥n del Proyecto

Este proyecto implementa un sistema de **fenotipado psicol√≥gico** para clasificaci√≥n binaria de **Ansiedad vs Depresi√≥n** en notas cl√≠nicas de pacientes paraguayos.

### Caracter√≠sticas Principales:

- **Reproducible**: Splits fijos (patient-level), seed 42, notebooks documentados
- **Sin Data Leakage**: Split por PACIENTES (no por casos), 0% overlap
- **Comparativo**: 3 baselines (rule-based, TF-IDF, BETO)
- **Interpretable**: Visualizaciones, reportes detallados, comentarios extensos
- **Limpio**: C√≥digo modularizado con `utils_shared.py`, sin duplicaci√≥n
- **Seguro**: Datos sensibles nunca se suben a git

### Contexto:

El proyecto adapta metodolog√≠as del **Spanish Psych Phenotyping** (Colombia) al contexto paraguayo, considerando:
- Variaciones dialectales del espa√±ol paraguayo
- Ruido en transcripciones cl√≠nicas (typos, abreviaciones)
- Desbalance de clases (70% depresi√≥n, 30% ansiedad)
- **Estructura longitudinal**: 90 pacientes con ~35 consultas cada uno

---

## Estructura del Proyecto

```
psych-phenotyping-paraguay/

 notebooks/ # Notebooks reproducibles
 00_setup.ipynb # [OK] Validaci√≥n de entorno
 01_eda_understanding.ipynb # EDA + genera ips_clean.csv
 02_create_splits.ipynb # Splits unificados (80/20)
 02_baseline_rule_based.ipynb # Baseline con patrones
 02_baseline_tfidf.ipynb # Baseline con char TF-IDF
 02_baseline_transformer_beto.ipynb # Baseline con BETO
 02_comparacion_resultados.ipynb # Comparaci√≥n visual
 utils_shared.py # Utilidades compartidas (324 l√≠neas)

 data/ # Datos del proyecto (NO en git)
 ips_raw.csv # Dataset original
 ips_clean.csv # Dataset limpio (generado por 01_eda)
 splits/ # Splits train/val (generados por 02_create_splits)
 dataset_base.csv # Dataset maestro con row_id
 train_indices.csv # √çndices de train (2500 ejemplos)
 val_indices.csv # √çndices de val (625 ejemplos)
 figs/ # Figuras generadas

 configs/ # Configuraciones
 config_PY.yml # Config del proyecto paraguayo

 Spanish_Psych_Phenotyping_PY/ # Fork del proyecto colombiano
 (subproyecto externo con .git propio)

 requirements.txt # Dependencias Python
 README.md # Este archivo
 .gitignore # Protecci√≥n de datos sensibles
```

---

## Flujo de Trabajo

```mermaid
graph LR
 A[ips_raw.csv] --> B[01_eda]
 B --> C[ips_clean.csv]
 C --> D[02_create_splits]
 D --> E[splits/]
 E --> F1[02_baseline_rule_based]
 E --> F2[02_baseline_tfidf]
 E --> F3[02_baseline_transformer_beto]
 F1 --> G[02_comparacion]
 F2 --> G
 F3 --> G
 G --> H[Resultados + Visualizaciones]
```

### Pipeline Detallado:

1. **00_setup.ipynb**: Validaci√≥n de dependencias, paths, estructura
2. **01_eda_understanding.ipynb**: 
   - EDA completo del dataset (incluye an√°lisis de pacientes)
   - Detecta estructura longitudinal (90 pacientes √ó 35 consultas)
   - **Limpieza aplicada a ips_clean.csv**:
     - ‚úÖ Normalizaci√≥n Unicode (NFC)
     - ‚úÖ Colapso de alargamientos (`ansiedaaaad` ‚Üí `ansiedaad`)
     - ‚úÖ Remoci√≥n de caracteres extra√±os
     - ‚úÖ **NUEVO**: Remoci√≥n de oraciones duplicadas DENTRO de cada texto
     - ‚úÖ Eliminaci√≥n de textos duplicados completos
     - ‚ùå NO lowercase (preserva tildes, may√∫sculas)
     - ‚ùå NO elimina puntuaci√≥n
   - Genera `ips_clean.csv` (usado por TODOS los baselines)
   - ‚ö†Ô∏è Si modificas esta limpieza, debes re-ejecutar TODOS los baselines
3. **02_create_splits.ipynb**:
   - **Split por PACIENTES** (no por casos) para evitar leakage
   - Estratificado por clase mayoritaria del paciente
   - 80/20 split (seed=42): 72 pacientes train / 18 val
   - Genera `dataset_base.csv`, `train_indices.csv`, `val_indices.csv`
   - **Verificaci√≥n**: 0% overlap de pacientes entre train/val
4. **02_baseline_*.ipynb**:
   - Cada baseline carga los mismos splits (patient-level)
   - Aplica su propia estrategia de preprocesamiento
   - Exporta predicciones y m√©tricas
   - **Importante**: Todos usan `data/splits/` para garantizar comparaci√≥n justa
5. **02_comparacion_resultados.ipynb**:
   - Compara m√©tricas de los 3 baselines
   - Visualizaciones (barplots, an√°lisis por clase)
   - Interpretaci√≥n de resultados

---

## Instalaci√≥n

### Requisitos Previos:
- Python 3.11+
- pip o conda

### Paso 1: Clonar repositorio
```bash
git clone https://github.com/manununhez/psych-phenotyping-paraguay.git
cd psych-phenotyping-paraguay
```

### Paso 2: Crear entorno virtual (recomendado)
```bash
python3 -m venv .venv
source .venv/bin/activate # En Windows: .venv\Scripts\activate
```

### Paso 3: Instalar dependencias
```bash
pip install -r requirements.txt
```

### Paso 4: Clonar fork del proyecto colombiano (solo si usas baseline rule-based)
```bash
git clone https://github.com/clarafrydman/Spanish_Psych_Phenotyping.git Spanish_Psych_Phenotyping_PY
```

### Paso 5: Colocar datos
```bash
# Colocar tu archivo ips_raw.csv en data/
cp /path/to/your/ips_raw.csv data/
```

### Paso 6: Ejecutar 00_setup.ipynb
Abre `notebooks/00_setup.ipynb` y ejecuta todas las celdas para validar la configuraci√≥n.

---

## Uso R√°pido

### Opci√≥n A: Flujo Completo (desde cero)

```bash
# 1. Validar setup
jupyter notebook notebooks/00_setup.ipynb

# 2. EDA y limpieza
jupyter notebook notebooks/01_eda_understanding.ipynb

# 3. Crear splits
jupyter notebook notebooks/02_create_splits.ipynb

# 4. Entrenar baselines (ejecutar los 3)
jupyter notebook notebooks/02_baseline_rule_based.ipynb
jupyter notebook notebooks/02_baseline_tfidf.ipynb
jupyter notebook notebooks/02_baseline_transformer_beto.ipynb

# 5. Comparar resultados
jupyter notebook notebooks/02_comparacion_resultados.ipynb
```

### Opci√≥n B: Solo Comparaci√≥n (si ya tienes splits)

```bash
# Si ya ejecutaste 01_eda y 02_create_splits:
jupyter notebook notebooks/02_baseline_*.ipynb
jupyter notebook notebooks/02_comparacion_resultados.ipynb
```

---

## Baselines Implementados

### 1. Rule-Based (Patrones + ConText)

**Estrategia**: Usa patrones JSON del fork colombiano + ConText para negaci√≥n

**Preprocesamiento**: LIGERO
- [OK] Preserva tildes y may√∫sculas (los patrones los necesitan)
- [OK] Colapsa alargamientos ("tristeee" ‚Üí "tristee")
- [X] No elimina puntuaci√≥n (ConText la usa)

**Justificaci√≥n**: Los patrones JSON est√°n dise√±ados para texto con estructura original.

**Pros**: Interpretable, r√°pido, sin entrenamiento 
**Contras**: Requiere mantenimiento manual de patrones

---

### 2. TF-IDF + SVM (Char n-grams 3-5)

**Estrategia**: Char-level TF-IDF (robusto a typos) + LinearSVC con class_weight='balanced'

**Preprocesamiento**: AGRESIVO
- [OK] Lowercase completo
- [OK] Elimina tildes (robustez ante errores)
- [OK] Marca negaciones ("no tengo" ‚Üí "no_tengo")
- [OK] Elimina s√≠mbolos especiales

**Justificaci√≥n**: 
- Char n-grams capturan "deprecion" ‚âà "depresion" (robustez a typos)
- Marca negaciones sin necesidad de ConText
- Est√°ndar de la industria para texto con ruido

**Pros**: Robusto a errores ortogr√°ficos, no requiere GPU 
**Contras**: No captura sem√°ntica compleja

---

### 3. BETO (RoBERTa en espa√±ol)

**Estrategia**: Fine-tuning de BETO-base (dccuchile/bert-base-spanish-wwm-cased)

**Preprocesamiento**: CONSERVADOR
- [OK] Preserva tildes, may√∫sculas, puntuaci√≥n
- [OK] Solo colapsa alargamientos
- [X] No lowercase (el modelo lo maneja)

**Justificaci√≥n**:
- BETO est√° preentrenado con texto "natural"
- Normalizar agresivamente = salirse de la distribuci√≥n de entrenamiento
- Papers muestran que "less is more" para transformers

**Pros**: Captura contexto y sem√°ntica, state-of-the-art 
**Contras**: Requiere GPU, m√°s lento

---

### 4. Dummy Baselines (Sanity Check)

**Estrategia**: Baselines triviales para validar que los modelos ML no est√°n overfitting

**Implementados**:
- **Dummy Majority**: Predice siempre la clase mayoritaria (Depresi√≥n)
- **Dummy Stratified**: Predice aleatoriamente respetando proporci√≥n de clases

**Justificaci√≥n**:
- Valida que los modelos ML capturan patrones discriminativos reales
- Est√°ndar en ML para descartar modelos que memorizan sin aprender
- Permite cuantificar mejora real sobre baseline trivial

**Ver**: `notebooks/02_baseline_dummy.ipynb`

---

### Archivos Generados:

Cada baseline genera:
- `{baseline}_predictions.csv`: Predicciones por ejemplo
- `{baseline}_eval.csv`: M√©tricas macro
- `{baseline}_classification_report.csv`: Reporte por clase
- `{baseline}_confusion_matrix.csv`: Matriz de confusi√≥n

**Ubicaci√≥n**: `data/` (todos los CSVs de resultados)

---

## üìä Resultados Principales

### Comparaci√≥n de Baselines (Macro F1 en validaci√≥n, n=646 casos, 18 pacientes)

| Modelo | F1 | Precision | Recall | Mejora vs Random |
|--------|-------|-----------|---------|------------------|
| **TF-IDF char(3,5)** | **0.755** | 0.746 | 0.768 | **+53.1%** ‚úÖ |
| **BETO (transformer)** | **0.742** | 0.736 | 0.748 | **+50.3%** ‚úÖ |
| **Rule-based (COL)** | **0.503** | 0.517 | 0.511 | **+2.0%** ‚ö†Ô∏è |
| Dummy (Stratified) | 0.493 | 0.496 | 0.495 | - |
| Dummy (Majority) | 0.429 | 0.375 | 0.500 | - |

### Interpretaci√≥n:

**‚úÖ Validaci√≥n exitosa:**
- TF-IDF y BETO superan **+50%** al baseline aleatorio ‚Üí capturan patrones reales (no overfitting)
- Performance equivalente entre TF-IDF (0.755) y BETO (0.742), diferencia de 1.3% no significativa
- El problema A/D es fundamentalmente l√©xico-discriminativo

**‚ö†Ô∏è Rule-based limitado:**
- Apenas supera baseline aleatorio (+2.0%) por cobertura cr√≠tica
- 78% de casos sin detecci√≥n (vocabulario colombiano ‚â† paraguayo)
- Recall en Ansiedad: 0.16 (detecta solo 1 de cada 5 casos)

**Archivos:**
- Tabla consolidada: `data/02_baselines_con_dummy.csv`
- Visualizaci√≥n: `data/figs/02_comparacion_con_dummy.png`
- An√°lisis completo: `RESULTADOS_BASELINES_README.md`
- Comparaci√≥n pre/post limpieza: `COMPARACION_ANTES_DESPUES_LIMPIEZA.md`

**Nota sobre preprocesamiento:**
> **Limpieza de oraciones duplicadas** (Nov 2025): Se removieron 43,938 oraciones duplicadas (52.7% de textos afectados, reducci√≥n 40.3% de caracteres). Los resultados ML se mantuvieron **id√©nticos** (TF-IDF 0.755, BETO 0.742), validando que las repeticiones eran ruido artificial. Rule-based mejor√≥ ligeramente (+1.4%). Ver `COMPARACION_ANTES_DESPUES_LIMPIEZA.md` para an√°lisis detallado.

---

## Decisiones de Dise√±o

### 1. ¬øPor qu√© 3 estrategias de preprocesamiento diferentes?

**Decisi√≥n**: Cada baseline usa preprocesamiento adaptado a su arquitectura.

**Razones**:
- **Rule-Based**: Necesita texto original para matching de patrones
- **TF-IDF**: Beneficia de normalizaci√≥n agresiva para reducir vocabulario
- **BETO**: Necesita texto similar al pretraining para funcionar bien

**Alternativa considerada**: Normalizaci√≥n √∫nica para todos ‚Üí Rechazada porque perjudica a rule-based y BETO.

### 2. ¬øPor qu√© char TF-IDF en lugar de word TF-IDF?

**Decisi√≥n**: Usar char n-grams (3-5) en lugar de word n-grams.

**Razones**:
- Datos cl√≠nicos tienen muchos typos: "anciedad", "deprecion"
- Char n-grams capturan overlap: "deprecion" y "depresion" comparten "pre", "epr", "rec"
- No requiere tokenizaci√≥n perfecta

**Alternativa considerada**: Word TF-IDF ‚Üí Rechazada por sensibilidad a errores ortogr√°ficos.

### 3. ¬øPor qu√© splits unificados en lugar de splits separados por baseline?

**Decisi√≥n**: Todos los baselines usan los mismos train/val indices.

**Razones**:
- **Comparabilidad**: Evaluamos en exactamente los mismos ejemplos
- **Reproducibilidad**: Seed fijo (42) garantiza resultados replicables
- **Simplicidad**: Un solo punto de verdad para los datos

**Alternativa considerada**: Splits diferentes ‚Üí Rechazada porque impide comparaci√≥n justa.

### 4. ¬øPor qu√© utils_shared.py?

**Decisi√≥n**: Centralizar funciones comunes en un m√≥dulo.

**Razones**:
- Elimina ~150 l√≠neas de c√≥digo duplicado
- Garantiza consistencia (todos usan mismas funciones)
- Facilita mantenimiento (cambio en 1 lugar)

**Impacto**: Reducci√≥n del 40% en c√≥digo duplicado.

### 5. ¬øPor qu√© split 80/20 en lugar de 70/15/15?

**Decisi√≥n**: Solo train/val, sin test separado.

**Razones**:
- Dataset peque√±o (~3K ejemplos): maximizar datos para train
- Validaci√≥n es suficiente para comparar baselines
- Test separado se puede crear despu√©s si es necesario

**Alternativa considerada**: 70/15/15 (train/val/test) ‚Üí Rechazada por dataset peque√±o.

### 6. ¬øPor qu√© patient-level split en lugar de split por casos?

**Decisi√≥n**: Split por PACIENTES (no por casos/consultas).

**Razones**:
- **Evita data leakage**: Dataset tiene 90 pacientes √ó 35 consultas promedio
- **Split por casos ‚Üí 100% leakage**: Todos los pacientes estar√≠an en train Y val
- **Cumple est√°ndares**: FDA, TRIPOD-AI requieren entidades independientes
- **Generalizaci√≥n real**: Simula clasificar pacientes NUEVOS (despliegue)

---

## Documentaci√≥n Adicional

- **[data/README.md](data/README.md)**: Descripci√≥n de archivos de datos
- **[notebooks/utils_shared.py](notebooks/utils_shared.py)**: Documentaci√≥n de funciones compartidas (324 l√≠neas)
- **Comentarios en notebooks**: Cada notebook tiene 50-80 l√≠neas de comentarios explicativos


---

## Autores

- **Manuel Nu√±ez** - [@manununhez](https://github.com/manununhez)

**Basado en**: [Spanish Psych Phenotyping](https://github.com/clarafrydman/Spanish_Psych_Phenotyping) por Clara Frydman

