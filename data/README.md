# Directorio de Datos

> [WARNING] **IMPORTANTE**: Este directorio NO est√° versionado en GitHub por privacidad de datos cl√≠nicos.

---

## Contenido del Directorio

### Archivos de Entrada (debes proveer)

#### `ips_raw.csv` (REQUERIDO)
- **Descripci√≥n**: Dataset original con notas cl√≠nicas sin procesar
- **Formato**: CSV con columnas:
 - `Motivo Consulta`: Texto de la nota cl√≠nica
 - `Tipo`: Etiqueta (Ansiedad/Depresi√≥n/Depresivo)
 - Otras columnas: metadata (fecha, paciente, etc.)
- **Tama√±o esperado**: ~3000-5000 registros
- **Fuente**: Sistema IPS o fuente cl√≠nica local
- **Privacidad**: NUNCA subir a git (protegido por .gitignore)

**C√≥mo obtenerlo**:
```bash
# Copiar tu dataset local
cp /path/to/your/ips_raw.csv data/ips_raw.csv
```

---

### Archivos Generados (autom√°ticamente por notebooks)

#### `ips_clean.csv` (generado por `01_eda_understanding.ipynb`)
- **Descripci√≥n**: Dataset limpio con preprocesamiento ligero
- **Formato**: CSV con columnas:
 - `id_paciente`: ID √∫nico del paciente
 - `fecha`: Fecha de la consulta
 - `texto`: Texto limpio (colapso de alargamientos, normalizaci√≥n de espacios)
 - `etiqueta`: Etiqueta normalizada (`ansiedad` o `depresion`)
- **Preprocesamiento aplicado**:
 - ‚úÖ Normalizaci√≥n Unicode (NFC)
 - ‚úÖ Normalizaci√≥n de etiquetas (`Depresivo` ‚Üí `depresion`)
 - ‚úÖ Colapso de alargamientos (`holaaa` ‚Üí `holaa`)
 - ‚úÖ Normalizaci√≥n de espacios
 - ‚úÖ **NUEVO**: Remoci√≥n de oraciones duplicadas DENTRO de cada texto
 - ‚úÖ Eliminaci√≥n de textos duplicados completos
 - ‚ùå NO lowercase (preserva tildes y may√∫sculas)
 - ‚ùå NO elimina puntuaci√≥n
- **Tama√±o**: ~3125 registros √∫nicos (despu√©s de deduplicaci√≥n)
- **Uso**: Entrada para `02_create_splits.ipynb` y TODOS los baselines
- **‚ö†Ô∏è IMPORTANTE**: Si modificas la limpieza en `01_eda_understanding.ipynb`, 
  debes RE-EJECUTAR todos los notebooks de baselines para mantener comparabilidad

---

#### `splits/` (generado por `02_create_splits.ipynb`)

Directorio con splits unificados para todos los baselines, con estrategia metodol√≥gica 60/20/20:

##### **Estrategia de Split 60/20/20 + Cross-Validation**

Split a nivel de **paciente** (no de casos) para eliminar data leakage:

| Conjunto | Casos | Pacientes | Prop√≥sito |
|----------|-------|-----------|-----------|
| **Train** | 1,849 (59.1%) | 54 | Entrenamiento modelos |
| **Dev** | 641 (20.5%) | 18 | Validaci√≥n single (contexto adicional) |
| **Test** | 637 (20.4%) | 18 | Evaluaci√≥n final ciega (reservado) |
| **CV 5-Fold** | 2,490 (79.6%) | 72 | **M√©trica principal** (Train+Dev combinados) |

**Caracter√≠sticas del split:**
- ‚úÖ **Zero leakage**: Un paciente solo aparece en UN conjunto (train, dev o test)
- ‚úÖ **Estratificado**: Por clase mayoritaria del paciente
- ‚úÖ **Reproducible**: Seed fijo 42
- ‚úÖ **CV patient-level stratified**: 5 folds en Train+Dev combinados

**Estrategia de evaluaci√≥n:**
1. **Cross-Validation 5-fold** (PRINCIPAL):
   - Usa Train+Dev combinados (2,490 casos, 72 pacientes)
   - Patient-level stratified, ~2,501 train / ~625 test por fold
   - Cada paciente evaluado exactamente 1 vez
   - IC95% bootstrapped (10,000 iteraciones) para significancia estad√≠stica
   - **M√©trica para paper/tesis:** F1 Macro (CV) ¬± std con IC95%

2. **Single dev evaluation** (CONTEXTO):
   - Validaci√≥n en dev set (641 casos, 18 pacientes)
   - √ötil para comparar consistencia con CV
   - Si dev ‚àà IC95% de CV ‚Üí split representativo ‚úÖ

3. **Test set hold-out** (RESERVADO):
   - Evaluaci√≥n final ciega (637 casos, 18 pacientes)
   - Solo usar para evaluaci√≥n final de mejor modelo
   - NO tocar hasta evaluaci√≥n final

**Justificaci√≥n metodol√≥gica:**
- **CV 5-fold es est√°ndar** para datasets peque√±os (maximiza uso de datos)
- El **dev set** permite validar consistencia (todos los modelos caen dentro IC95%)
- El **test set** se reserva ciego para evaluaci√≥n final contra baselines
- Split patient-level evita que textos del mismo paciente aparezcan en train y dev/test
- **IC95% de CV** cuantifica incertidumbre real del modelo (critical para paper/tesis)

##### `splits/train_indices.csv`
- **Descripci√≥n**: √çndices (row_id) del conjunto de entrenamiento
- **Formato**: CSV con una columna `row_id`
- **Tama√±o**: 1,863 √≠ndices (60%)
- **Uso**: Entrenar modelos ML y explorar vocabulario para Concept_PY

##### `splits/dev_indices.csv`
- **Descripci√≥n**: √çndices (row_id) del conjunto de desarrollo/validaci√≥n
- **Formato**: CSV con una columna `row_id`
- **Tama√±o**: 646 √≠ndices (20%)
- **Uso**: Validaci√≥n iterativa durante desarrollo de Concept_PY, ajuste de hiperpar√°metros

##### `splits/test_indices.csv`
- **Descripci√≥n**: √çndices (row_id) del conjunto de test (reservado)
- **Formato**: CSV con una columna `row_id`
- **Tama√±o**: 646 √≠ndices (20%)
- **Uso**: Evaluaci√≥n final ciega de Concept_PY vs baselines (NO USAR hasta evaluaci√≥n final)

**¬øPor qu√© separar dataset e √≠ndices?**
- [OK] Permite que cada baseline aplique su propio preprocesamiento
- [OK] Un √∫nico dataset maestro garantiza consistencia
- [OK] √çndices ligeros (solo IDs) facilitan reproducibilidad

---

#### Archivos de Resultados (generados por `02_baseline_*.ipynb`)

Cada baseline genera 4 archivos:

##### `{baseline}_predictions.csv`
- **Contenido**: Predicciones por ejemplo
- **Columnas**: `row_id`, `texto`, `true_label`, `pred_label`
- **Uso**: An√°lisis de errores

##### `{baseline}_eval.csv`
- **Contenido**: M√©tricas macro agregadas
- **Columnas**: `macro_f1`, `macro_precision`, `macro_recall`, `n`
- **Uso**: Comparaci√≥n r√°pida entre baselines

##### `{baseline}_classification_report.csv`
- **Contenido**: Reporte detallado por clase
- **Columnas**: `precision`, `recall`, `f1-score`, `support` por clase
- **Uso**: An√°lisis por clase (Depresi√≥n vs Ansiedad)

##### `{baseline}_confusion_matrix.csv`
- **Contenido**: Matriz de confusi√≥n
- **Formato**: Filas = true, Columnas = pred
- **Uso**: Visualizaci√≥n de errores

**Baselines que generan estos archivos**:
- `rule_based_*.csv`
- `tfidf_*.csv`
- `beto_*.csv`

---

#### Archivos de EDA (generados por `01_eda_understanding.ipynb`)

##### An√°lisis de n-gramas:
- `eda_top_unigrams.csv`: Top 20 palabras m√°s frecuentes
- `eda_top_bigrams.csv`: Top 20 bigramas m√°s frecuentes
- `eda_top_trigrams.csv`: Top 20 trigramas m√°s frecuentes
- `eda_ans_unigrams.csv`: Unigramas espec√≠ficos de Ansiedad
- `eda_ans_bigrams.csv`: Bigramas espec√≠ficos de Ansiedad
- `eda_dep_unigrams.csv`: Unigramas espec√≠ficos de Depresi√≥n
- `eda_dep_bigrams.csv`: Bigramas espec√≠ficos de Depresi√≥n

##### An√°lisis de ruido:
- `eda_noise_stats_overall.csv`: Estad√≠sticas de ruido general
- `eda_noise_stats_by_class.csv`: Estad√≠sticas de ruido por clase

---

#### `figs/` (generado por notebooks con visualizaciones)

Directorio con figuras generadas:
- Distribuciones de clases
- Wordclouds
- Gr√°ficos de comparaci√≥n de baselines
- Matrices de confusi√≥n visualizadas

---

## Flujo de Datos

```

 ips_raw.csv (entrada manual)

 01_eda_understanding.ipynb
 ‚Üì

ips_clean.csv (limpieza ligera)

 02_create_splits.ipynb
 ‚Üì

 splits/ 
 dataset_base.csv 
 train_indices.csv
 val_indices.csv 

 02_baseline_*.ipynb
 ‚Üì

 Resultados por baseline
 predictions.csv 
 eval.csv 
 report.csv 
 confusion_matrix.csv

```

---

## Tama√±os Esperados

| Archivo | Tama√±o Aproximado | Registros |
|---------|-------------------|-----------|
| `ips_raw.csv` | ~2-5 MB | ~3000-5000 |
| `ips_clean.csv` | ~1-3 MB | ~3125 |
| `splits/dataset_base.csv` | ~1-3 MB | 3125 |
| `splits/train_indices.csv` | ~50 KB | 2500 |
| `splits/val_indices.csv` | ~15 KB | 625 |
| `*_predictions.csv` | ~500 KB | 625 (val) |
| `*_eval.csv` | ~1 KB | 1 fila |

---

## üîç Problemas de Calidad del Dataset Identificados

Durante el desarrollo del proyecto, se identificaron dos problemas cr√≠ticos de calidad de datos que afectan significativamente los resultados:

### **1. Problema: Oraciones Duplicadas Intra-Texto (40.3% del corpus)**

**Descripci√≥n**: El dataset original (`ips_raw.csv`) conten√≠a 43,938 oraciones duplicadas **dentro del mismo texto**, resultado de:
- Errores de transcripci√≥n (copiar-pegar repetido)
- Campos de formulario duplicados
- Artefactos del sistema IPS

**Impacto**:
- ‚ùå Sobre-representaci√≥n artificial de ciertos patrones
- ‚ùå Bias en m√©tricas de vocabulario (TF-IDF inflado)
- ‚ùå Modelos aprendiendo a detectar duplicados en lugar de s√≠ntomas

**Soluci√≥n**: 
- ‚úÖ Implementada en `01_eda_understanding.ipynb`
- ‚úÖ Deduplicaci√≥n de oraciones intra-texto (preservando estructura)
- ‚úÖ Dataset limpio: `ips_clean.csv` (3,127 casos vs 3,155 originales)
- ‚úÖ 43,938 oraciones duplicadas removidas (40.3% del corpus de oraciones)

**Resultados**:
- Modelos entrenados con `ips_clean.csv` muestran m√©tricas m√°s realistas
- Vocabulario ahora refleja diversidad real del dataset

---

### **2. Problema: Artifact de Muestreo en Validaci√≥n (Sampling Variance)**

**Descripci√≥n**: Al cambiar de split 80/20 a 60/20/20, se observ√≥ una mejora "sospechosa" de +14.6% en F1:
- Val 80/20: F1 = 0.755 (27 pacientes)
- Dev 60/20/20: F1 = 0.866 (18 pacientes)

**Investigaci√≥n**:
- ‚úÖ An√°lisis de overlap de pacientes: Solo **11.1% compartidos** (3 de 27 pacientes)
- ‚úÖ 24 pacientes solo en val 80/20, 15 pacientes solo en dev 60/20/20
- ‚úÖ Evaluaci√≥n en **test set** (hold-out final): F1 = 0.786

**Conclusi√≥n**:
- ‚ùå La mejora +14.6% fue un **artifact de muestreo**, no mejora real
- ‚úÖ Los 15 pacientes en dev 60/20/20 eran m√°s f√°ciles por azar (ratio D/A m√°s balanceado: 1.84 vs 2.75)
- ‚úÖ F1 real del modelo est√° en rango **0.75-0.80** (confirmado por test set)

**Lecciones aprendidas**:
- ‚ö†Ô∏è Con **solo 90 pacientes totales**, hay alta varianza por muestreo
- ‚ö†Ô∏è Diferentes pacientes en validaci√≥n pueden dar ¬±10-15% de F1 por azar
- ‚úÖ **Test set evaluation** es cr√≠tico para validar resultados
- ‚úÖ Recomendaci√≥n: Cross-validation para estimar F1 con intervalos de confianza

**Evidencia documentada**:
- An√°lisis completo en notebooks
- Comparaci√≥n de caracter√≠sticas de pacientes √∫nicos por split
- Evaluaci√≥n en 3 conjuntos: val 80/20, dev 60/20/20, test 60/20/20

---

### **Recomendaciones para Futuros Trabajos**

1. **Expansi√≥n del dataset**: 
   - Objetivo: 200-300 pacientes para reducir varianza
   - Priorizar balance Depresi√≥n/Ansiedad (actualmente 70/30)

2. **Validaci√≥n robusta**:
   - Usar **cross-validation 5-fold** a nivel de pacientes
   - Reportar F1 con IC95% en lugar de punto √∫nico
   - Siempre validar en test set hold-out antes de conclusiones

3. **Calidad de datos**:
   - Auditor√≠a de textos cortos (<200 chars): 1.9-2.5% de casos
   - Revisi√≥n con psiquiatras de casos ambiguos
   - Verificaci√≥n manual de etiquetas en casos lim√≠trofes

---

## Privacidad y Seguridad

### [OK] Archivos Protegidos (NO se suben a git):

Todos los archivos `.csv`, `.xlsx`, `.json` en este directorio est√°n protegidos por `.gitignore`:

```gitignore
data/*.csv
data/*.xlsx
data/*.json
data/splits/
data/figs/
```

### [X] NUNCA subir a git:
- ips_raw.csv (datos originales)
- ips_clean.csv (datos procesados)
- Cualquier archivo con informaci√≥n de pacientes

### [OK] S√ç se versiona:
- Este README.md (documentaci√≥n)

---

## Setup para Google Colab

Si trabajas en Google Colab:

```python
from google.colab import drive
drive.mount('/content/drive')

# Apuntar DATA_PATH a tu Drive
DATA_PATH = Path("/content/drive/MyDrive/psych-data")
```

---

## FAQ

### ¬øQu√© pasa si no tengo ips_raw.csv?

Ejecuta `00_setup.ipynb` y ver√°s un error claro:
```
[X] Falta archivo cr√≠tico:
 - Colocar ips_raw.csv en data/
```

### ¬øPuedo usar otro nombre para el archivo de entrada?

S√≠, pero necesitas modificar `01_eda_understanding.ipynb`:
```python
INPUT_FILE = DATA_PATH / "tu_archivo.csv"
```

### ¬øC√≥mo regenero ips_clean.csv si lo borr√©?

Ejecuta `01_eda_understanding.ipynb` de nuevo.

### ¬øC√≥mo regenero los splits?

Ejecuta `02_create_splits.ipynb` de nuevo. Los √≠ndices ser√°n los mismos (seed=42).

### ¬øPuedo cambiar el split 80/20?

S√≠, modifica en `02_create_splits.ipynb`:
```python
TEST_SIZE = 0.3 # Para split 70/30
```

### ¬øLos datos est√°n balanceados?

No. La distribuci√≥n natural es:
- Depresi√≥n: ~70% (2200 ejemplos en train)
- Ansiedad: ~30% (925 ejemplos en train)

Los baselines usan `class_weight='balanced'` para compensar.

---

## Soporte

Si tienes problemas con los datos:

1. Verifica que `ips_raw.csv` existe: `ls -lh data/ips_raw.csv`
2. Ejecuta `00_setup.ipynb` para diagn√≥stico completo
3. Revisa logs de errores en los notebooks
4. Abre un issue en GitHub (sin incluir datos sensibles)

---

**√öltima actualizaci√≥n**: Noviembre 2025