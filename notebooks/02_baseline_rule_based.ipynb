{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc45479",
   "metadata": {},
   "source": [
    "# 02_baseline_rule_based ‚Äî Binario A/D\n",
    "\n",
    "**Objetivo:** baseline **rule-based** usando el fork del proyecto colombiano (solo **Ansiedad/Depresi√≥n**) para obtener una primera l√≠nea de referencia.  \n",
    "**Justificaci√≥n:** las reglas permiten:\n",
    "- establecer un punto de partida interpretable (trazabilidad por JSON/patrones),\n",
    "- detectar fallos sistem√°ticos del dataset (typos, negaci√≥n, expresiones locales),\n",
    "- guiar el dise√±o del *cleaning* y la selecci√≥n de fenotipos relevantes para A/D.\n",
    "\n",
    "> Nota: mantenemos **preprocesamiento ligero** para no romper *ConText* ni *TargetMatcher*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c9b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ DATA_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data\n",
      "üìÅ FORK_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY\n",
      "‚ÑπÔ∏è  Este baseline carga datos desde data/splits/ (generados por 02_create_splits.ipynb)\n"
     ]
    }
   ],
   "source": [
    "# === Paths / Globals (auto-detect) ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re, unicodedata, os\n",
    "\n",
    "# Rutas y entorno\n",
    "BASE_PATH = Path.cwd()\n",
    "if BASE_PATH.name == \"notebooks\":\n",
    "    BASE_PATH = BASE_PATH.parent\n",
    "\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "FORK_PATH = BASE_PATH / \"Spanish_Psych_Phenotyping_PY\"\n",
    "\n",
    "# Reuse existing globals if present (from your 02_baselines.ipynb)\n",
    "DATA_PATH = Path(DATA_PATH) if 'DATA_PATH' in globals() else Path('data')\n",
    "FORK_PATH = Path(FORK_PATH) if 'FORK_PATH' in globals() else Path('Spanish_Psych_Phenotyping_PY')\n",
    "DATA_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"üìÅ DATA_PATH:\", DATA_PATH)\n",
    "print(\"üìÅ FORK_PATH:\", FORK_PATH)\n",
    "print(\"‚ÑπÔ∏è  Este baseline carga datos desde data/splits/ (generados por 02_create_splits.ipynb)\")\n",
    "\n",
    "# --- Columnas esperadas en dataset_base.csv ---\n",
    "TEXT_COL = \"texto\"\n",
    "LABEL_COL = \"etiqueta\"\n",
    "\n",
    "# Column preferences (honor globals if defined)\n",
    "TEXT_COL  = TEXT_COL  if 'TEXT_COL'  in globals() else None\n",
    "LABEL_COL = LABEL_COL if 'LABEL_COL' in globals() else None\n",
    "\n",
    "def _guess_text_col(df):\n",
    "    if TEXT_COL and TEXT_COL in df.columns: \n",
    "        return TEXT_COL\n",
    "    for c in ['texto','Motivo Consulta','original_motivo_consulta','text']:\n",
    "        if c in df.columns: return c\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == 'O': return c\n",
    "    raise ValueError(\"No se encontr√≥ columna de texto.\")\n",
    "\n",
    "def _guess_label_col(df):\n",
    "    if LABEL_COL and LABEL_COL in df.columns: \n",
    "        return LABEL_COL\n",
    "    for c in ['etiqueta','Tipo','label','target','y','clase']:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "def _norm_label_bin(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    return {'depresivo':'depresion'}.get(s, s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150cec7",
   "metadata": {},
   "source": [
    "## 1) Carga y preprocesamiento **ligero** (conserva tildes y casing, colapsa alargamientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489012c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Splits cargados: Train=2500 | Val=625\n",
      "Train distribuci√≥n:\n",
      "etiqueta\n",
      "depresion    1760\n",
      "ansiedad      740\n",
      "Name: count, dtype: int64\n",
      "Val distribuci√≥n:\n",
      "etiqueta\n",
      "depresion    440\n",
      "ansiedad     185\n",
      "Name: count, dtype: int64\n",
      "Train distribuci√≥n:\n",
      "etiqueta\n",
      "depresion    1760\n",
      "ansiedad      740\n",
      "Name: count, dtype: int64\n",
      "Val distribuci√≥n:\n",
      "etiqueta\n",
      "depresion    440\n",
      "ansiedad     185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, re, unicodedata\n",
    "\n",
    "# === CARGAR SPLITS UNIFICADOS ===\n",
    "SPLITS_PATH = DATA_PATH / \"splits\"\n",
    "dataset_base = pd.read_csv(SPLITS_PATH / 'dataset_base.csv')\n",
    "train_indices = pd.read_csv(SPLITS_PATH / 'train_indices.csv')['row_id'].values\n",
    "val_indices = pd.read_csv(SPLITS_PATH / 'val_indices.csv')['row_id'].values\n",
    "\n",
    "print(f\"‚úÖ Splits cargados: Train={len(train_indices)} | Val={len(val_indices)}\")\n",
    "\n",
    "text_col  = _guess_text_col(dataset_base)\n",
    "label_col = _guess_label_col(dataset_base)\n",
    "\n",
    "# Preprocesamiento ligero para rule-based (conserva tildes/casing, colapsa alargamientos)\n",
    "_RE_MULTI = re.compile(r'(.)\\1{2,}')\n",
    "def clean_text_rb(s: str) -> str:\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip()\n",
    "    s = unicodedata.normalize(\"NFC\", s)\n",
    "    s = _RE_MULTI.sub(r'\\1\\1', s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "dataset_base['texto_rb'] = dataset_base[text_col].map(clean_text_rb)\n",
    "\n",
    "# Separar train y val usando √≠ndices guardados\n",
    "df_train = dataset_base[dataset_base['row_id'].isin(train_indices)].copy()\n",
    "df_val = dataset_base[dataset_base['row_id'].isin(val_indices)].copy()\n",
    "\n",
    "print(f\"Train distribuci√≥n:\\n{df_train[label_col].value_counts()}\")\n",
    "print(f\"Val distribuci√≥n:\\n{df_val[label_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60611719",
   "metadata": {},
   "source": [
    "## 2) Ejecutar fork (perfil `col`) con solo Ansiedad/Depresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b09ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: /opt/anaconda3/bin/python /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY/cli.py --profile col --config /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY/configs/col_config.yml --input /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/ips_clean_tmp.csv --output /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv\n",
      "Components in NLP pipeline:\n",
      "\t- tok2vec\n",
      "\t- morphologizer\n",
      "\t- attribute_ruler\n",
      "\t- lemmatizer\n",
      "\t- medspacy_pyrush\n",
      "\t- medspacy_target_matcher\n",
      "\t- medspacy_context\n",
      "Concepts included (by folder): Ansiedad, Depresion\n",
      "Rule categories loaded: Abulia, Abusodesustancias, Agitacinpsicomotora, Alteracindelapercepcindepesoofiguracorporal, AngustiaMiedoTemor, Anhedonia, Animodeprimido, Animoexpansivo, Ansiedad, Apata, Apetitoaumentode, Apetitodisminucinde, Autolesin, Bajaconcentracin, Bajaenerga, Culpa, Desesperanza, Efectosadversos, Fatiga, Ideacinsuicida, Ideasdemuerte, Intentosuicida, Irritabilidad, Labilidademocional, Llantofcil, Malahigienepersonal, Negativismo, RetraimientosocialAislamiento, Retrasopsicomotor, Sntomasafectivos, Sntomasansiososgenerales, Sntomasdepresivosgenerales, SntomassomticosEjemplos\n",
      "Total target rules added: 229\n",
      "‚úÖ Guardado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv  | filas=625\n",
      "\n",
      "Components in NLP pipeline:\n",
      "\t- tok2vec\n",
      "\t- morphologizer\n",
      "\t- attribute_ruler\n",
      "\t- lemmatizer\n",
      "\t- medspacy_pyrush\n",
      "\t- medspacy_target_matcher\n",
      "\t- medspacy_context\n",
      "Concepts included (by folder): Ansiedad, Depresion\n",
      "Rule categories loaded: Abulia, Abusodesustancias, Agitacinpsicomotora, Alteracindelapercepcindepesoofiguracorporal, AngustiaMiedoTemor, Anhedonia, Animodeprimido, Animoexpansivo, Ansiedad, Apata, Apetitoaumentode, Apetitodisminucinde, Autolesin, Bajaconcentracin, Bajaenerga, Culpa, Desesperanza, Efectosadversos, Fatiga, Ideacinsuicida, Ideasdemuerte, Intentosuicida, Irritabilidad, Labilidademocional, Llantofcil, Malahigienepersonal, Negativismo, RetraimientosocialAislamiento, Retrasopsicomotor, Sntomasafectivos, Sntomasansiososgenerales, Sntomasdepresivosgenerales, SntomassomticosEjemplos\n",
      "Total target rules added: 229\n",
      "‚úÖ Guardado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv  | filas=625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, yaml\n",
    "from pathlib import Path\n",
    "\n",
    "cfg_dir = FORK_PATH/'configs'\n",
    "cfg_dir.mkdir(parents=True, exist_ok=True)\n",
    "col_cfg = cfg_dir/'col_config.yml'\n",
    "fenos_yml = cfg_dir/'fenotipos.yml'\n",
    "\n",
    "# Forzar solo Ansiedad/Depresion en el fork\n",
    "cfg = {}\n",
    "if col_cfg.exists():\n",
    "    cfg = yaml.safe_load(col_cfg.read_text(encoding='utf-8')) or {}\n",
    "cfg['text_column'] = 'texto_rb'\n",
    "col_cfg.write_text(yaml.safe_dump(cfg, allow_unicode=True), encoding='utf-8')\n",
    "\n",
    "fen = {}\n",
    "if fenos_yml.exists():\n",
    "    fen = yaml.safe_load(fenos_yml.read_text(encoding='utf-8')) or {}\n",
    "fen['active_concepts'] = ['Ansiedad','Depresion']\n",
    "fenos_yml.write_text(yaml.safe_dump(fen, allow_unicode=True), encoding='utf-8')\n",
    "\n",
    "cli_py = FORK_PATH/'cli.py'\n",
    "main_py = FORK_PATH/'main.py'\n",
    "runner = cli_py if cli_py.exists() else main_py\n",
    "assert runner.exists(), \"No se encontr√≥ cli.py ni main.py en el fork.\"\n",
    "\n",
    "# Crear temp input solo con val set (para evaluar)\n",
    "tmp_in = DATA_PATH/'ips_clean_tmp.csv'\n",
    "df_val[['texto_rb', label_col]].rename(columns={'texto_rb':'texto_rb'}).to_csv(tmp_in, index=False, encoding='utf-8')\n",
    "\n",
    "# Salidas estandarizadas (comparables)\n",
    "rule_pred_csv   = DATA_PATH/'rule_based_predictions.csv'\n",
    "rule_report_csv = DATA_PATH/'rule_based_classification_report.csv'\n",
    "rule_eval_csv   = DATA_PATH/'rule_based_eval.csv'\n",
    "rule_cm_csv     = DATA_PATH/'rule_based_confusion_matrix.csv'\n",
    "\n",
    "cmd = [sys.executable, str(runner), '--profile','col', '--config', str(col_cfg),\n",
    "       '--input', str(tmp_in), '--output', str(rule_pred_csv)]\n",
    "print(\"CMD:\", \" \".join(map(str,cmd)))\n",
    "ret = subprocess.run(cmd, check=False, capture_output=True, text=True)\n",
    "print(ret.stdout)\n",
    "if ret.returncode != 0:\n",
    "    print(ret.stderr)\n",
    "    raise RuntimeError(f\"CLI termin√≥ con c√≥digo {ret.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb66af",
   "metadata": {},
   "source": [
    "## 3) Evaluaci√≥n **binaria** y exportables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84dbc18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exportados:\n",
      " - Predicciones: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv\n",
      " - Reporte: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_classification_report.csv\n",
      " - M√©tricas: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_eval.csv\n",
      " - Matriz: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_confusion_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, unicodedata as _ud\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "preds = pd.read_csv(rule_pred_csv)\n",
    "if 'pred_label' not in preds.columns:\n",
    "    raise ValueError(\"El output del fork no contiene 'pred_label'.\")\n",
    "\n",
    "def _norm_txt(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = _ud.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    return s\n",
    "\n",
    "y_pred = preds['pred_label'].map(_norm_txt)\n",
    "y_true = df_val[label_col].map(_norm_txt)\n",
    "\n",
    "# En caso de que el fork devuelva algo fuera de A/D, lo mapeamos a la clase mayoritaria para evaluar binario\n",
    "allowed = {'ansiedad','depresion'}\n",
    "majority = y_true.value_counts().idxmax()\n",
    "y_pred = y_pred.where(y_pred.isin(allowed), majority)\n",
    "\n",
    "classes = ['depresion','ansiedad']\n",
    "\n",
    "pd.DataFrame(classification_report(y_true, y_pred, labels=classes, output_dict=True, zero_division=0)).transpose()  .to_csv(rule_report_csv, index=True, encoding='utf-8')\n",
    "\n",
    "pd.DataFrame([{\n",
    "    'macro_f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'macro_precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'macro_recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'n': int(len(y_true))\n",
    "}]).to_csv(rule_eval_csv, index=False, encoding='utf-8')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "pd.DataFrame(cm, index=[f'true_{c}' for c in classes], columns=[f'pred_{c}' for c in classes]).to_csv(rule_cm_csv)\n",
    "\n",
    "print(\"‚úÖ Exportados:\")\n",
    "print(\" - Predicciones:\", rule_pred_csv)\n",
    "print(\" - Reporte:\", rule_report_csv)\n",
    "print(\" - M√©tricas:\", rule_eval_csv)\n",
    "print(\" - Matriz:\", rule_cm_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
