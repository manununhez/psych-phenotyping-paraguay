{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc45479",
   "metadata": {},
   "source": [
    "# 02_baseline_rule_based â€” Binario A/D\n",
    "\n",
    "**Objetivo:** baseline **rule-based** usando el fork del proyecto colombiano (solo **Ansiedad/DepresiÃ³n**) para obtener una primera lÃ­nea de referencia.  \n",
    "**JustificaciÃ³n:** las reglas permiten:\n",
    "- establecer un punto de partida interpretable (trazabilidad por JSON/patrones),\n",
    "- detectar fallos sistemÃ¡ticos del dataset (typos, negaciÃ³n, expresiones locales),\n",
    "- guiar el diseÃ±o del *cleaning* y la selecciÃ³n de fenotipos relevantes para A/D.\n",
    "\n",
    "> Nota: mantenemos **preprocesamiento ligero** para no romper *ConText* ni *TargetMatcher*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75c9b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Utilizando utils_shared.py\n",
      "âœ… Paths configurados:\n",
      "   BASE_PATH:   /Users/manuelnunez/Projects/psych-phenotyping-paraguay\n",
      "   DATA_PATH:   /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data\n",
      "   FORK_PATH:   /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY\n",
      "   SPLITS_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Setup: Paths, Imports, y Utilidades Compartidas\n",
    "# ===============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re, unicodedata, os\n",
    "\n",
    "# Intentar importar utilidades compartidas\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.insert(0, str(Path.cwd().parent))\n",
    "    from utils_shared import setup_paths, guess_text_col, guess_label_col, normalize_label\n",
    "    print(\"âœ… Utilizando utils_shared.py\")\n",
    "    \n",
    "    # Setup de paths centralizado\n",
    "    paths = setup_paths()\n",
    "    BASE_PATH = paths['BASE_PATH']\n",
    "    DATA_PATH = paths['DATA_PATH']\n",
    "    FORK_PATH = paths['FORK_PATH']\n",
    "    SPLITS_PATH = paths['SPLITS_PATH']\n",
    "    \n",
    "    # Usar funciones centralizadas\n",
    "    _guess_text_col = guess_text_col\n",
    "    _guess_label_col = guess_label_col\n",
    "    _norm_label_bin = normalize_label\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ utils_shared.py no encontrado, usando funciones locales\")\n",
    "    \n",
    "    # Setup manual de paths\n",
    "    BASE_PATH = Path.cwd()\n",
    "    if BASE_PATH.name == \"notebooks\":\n",
    "        BASE_PATH = BASE_PATH.parent\n",
    "    \n",
    "    DATA_PATH = BASE_PATH / \"data\"\n",
    "    FORK_PATH = BASE_PATH / \"Spanish_Psych_Phenotyping_PY\"\n",
    "    SPLITS_PATH = DATA_PATH / \"splits\"\n",
    "    \n",
    "    DATA_PATH.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Funciones helper locales\n",
    "    def _guess_text_col(df):\n",
    "        for c in [\"texto\", \"text\", \"comment\", \"comentario\"]:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return df.columns[0]\n",
    "    \n",
    "    def _guess_label_col(df):\n",
    "        for c in [\"etiqueta\", \"label\", \"category\"]:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return df.columns[1] if len(df.columns) > 1 else df.columns[-1]\n",
    "    \n",
    "    def _norm_label_bin(s):\n",
    "        if pd.isna(s): \n",
    "            return \"\"\n",
    "        s = str(s).strip().lower()\n",
    "        s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "        return {'depresivo': 'depresion'}.get(s, s)\n",
    "\n",
    "# Validar existencia de directorios crÃ­ticos\n",
    "if not FORK_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ Fork no encontrado en {FORK_PATH}\\n\"\n",
    "        f\"   Este baseline requiere Spanish_Psych_Phenotyping_PY/\"\n",
    "    )\n",
    "\n",
    "if not SPLITS_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ Splits no encontrados en {SPLITS_PATH}\\n\"\n",
    "        f\"   Debes ejecutar primero: 02_create_splits.ipynb\"\n",
    "    )\n",
    "\n",
    "print(f\"âœ… Paths configurados:\")\n",
    "print(f\"   BASE_PATH:   {BASE_PATH}\")\n",
    "print(f\"   DATA_PATH:   {DATA_PATH}\")\n",
    "print(f\"   FORK_PATH:   {FORK_PATH}\")\n",
    "print(f\"   SPLITS_PATH: {SPLITS_PATH}\")\n",
    "\n",
    "# Columnas esperadas en dataset_base.csv\n",
    "TEXT_COL = \"texto\"\n",
    "LABEL_COL = \"etiqueta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150cec7",
   "metadata": {},
   "source": [
    "## 1) Carga y preprocesamiento **ligero** (conserva tildes y casing, colapsa alargamientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "489012c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Splits cargados desde /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits/:\n",
      "   Train: 2500 ejemplos\n",
      "   Val:   626 ejemplos\n",
      "   Total: 3126 ejemplos en dataset_base.csv\n",
      "\n",
      "ðŸ“‹ Columnas detectadas: texto='texto', label='etiqueta'\n",
      "\n",
      "ðŸ§¹ Aplicado preprocesamiento ligero (conserva tildes/mayÃºsculas)\n",
      "   Ejemplo antes: Reposicion de medicacion 2) EXAMEN FISICO GRAL. Y GINECOLOGICO PESO ( ) TALLA ( ...\n",
      "   Ejemplo despuÃ©s: Reposicion de medicacion 2) EXAMEN FISICO GRAL. Y GINECOLOGICO PESO ( ) TALLA ( ...\n",
      "\n",
      "ðŸ“Š Splits creados:\n",
      "\n",
      "Train (2500 ejemplos):\n",
      "   depresion: 1760\n",
      "   ansiedad: 740\n",
      "\n",
      "Val (626 ejemplos):\n",
      "   depresion: 441\n",
      "   ansiedad: 185\n",
      "\n",
      "ðŸ§¹ Aplicado preprocesamiento ligero (conserva tildes/mayÃºsculas)\n",
      "   Ejemplo antes: Reposicion de medicacion 2) EXAMEN FISICO GRAL. Y GINECOLOGICO PESO ( ) TALLA ( ...\n",
      "   Ejemplo despuÃ©s: Reposicion de medicacion 2) EXAMEN FISICO GRAL. Y GINECOLOGICO PESO ( ) TALLA ( ...\n",
      "\n",
      "ðŸ“Š Splits creados:\n",
      "\n",
      "Train (2500 ejemplos):\n",
      "   depresion: 1760\n",
      "   ansiedad: 740\n",
      "\n",
      "Val (626 ejemplos):\n",
      "   depresion: 441\n",
      "   ansiedad: 185\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Carga de Datos y Preprocesamiento LIGERO (Rule-Based)\n",
    "# ===============================================================\n",
    "#\n",
    "# ESTRATEGIA DE PREPROCESAMIENTO: CONSERVADORA (mÃ­nimo)\n",
    "#\n",
    "# Â¿Por quÃ© preprocesamiento ligero?\n",
    "#\n",
    "# 1. **Preserva tildes y mayÃºsculas**:\n",
    "#    - Los patrones JSON del fork usan \"DepresiÃ³n\", \"Ansiedad\" con tildes\n",
    "#    - ConText y TargetMatcher son case-sensitive en algunos contextos\n",
    "#    - Normalizar agresivamente = romper el matching de patrones\n",
    "#\n",
    "# 2. **Solo colapsa alargamientos**:\n",
    "#    - \"holaaa\" â†’ \"holaa\" (mantiene Ã©nfasis sin perder matching)\n",
    "#    - Usuarios escriben \"estabaaa tristeee\" con mÃºltiples letras\n",
    "#    - Patrones no capturan \"tristeeeee\" pero sÃ­ \"tristee\"\n",
    "#\n",
    "# 3. **Normaliza espacios**:\n",
    "#    - Colapsa mÃºltiples espacios en uno solo\n",
    "#    - Elimina espacios al inicio/final\n",
    "#    - No afecta matching pero limpia entrada\n",
    "#\n",
    "# Â¿QuÃ© NO hace este preprocesamiento?\n",
    "# - âŒ No convierte a minÃºsculas (rompe patrones)\n",
    "# - âŒ No elimina tildes/acentos (rompe patrones)\n",
    "# - âŒ No elimina puntuaciÃ³n (ConText la usa)\n",
    "# - âŒ No hace stemming/lemmatizaciÃ³n (no necesario para reglas)\n",
    "#\n",
    "# ComparaciÃ³n con otros baselines:\n",
    "# - TF-IDF: Preprocesamiento agresivo (lowercase, sin tildes, sin puntuaciÃ³n)\n",
    "# - BETO: Solo tokenizaciÃ³n (el modelo maneja mayÃºsculas/tildes)\n",
    "# - Rule-Based: Conservador (preserva estructura original)\n",
    "#\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd, re, unicodedata\n",
    "\n",
    "# Cargar splits unificados desde 02_create_splits.ipynb\n",
    "dataset_base = pd.read_csv(SPLITS_PATH / 'dataset_base.csv')\n",
    "train_indices = pd.read_csv(SPLITS_PATH / 'train_indices.csv')['row_id'].values\n",
    "val_indices = pd.read_csv(SPLITS_PATH / 'val_indices.csv')['row_id'].values\n",
    "\n",
    "print(f\"âœ… Splits cargados desde {SPLITS_PATH}/:\")\n",
    "print(f\"   Train: {len(train_indices)} ejemplos\")\n",
    "print(f\"   Val:   {len(val_indices)} ejemplos\")\n",
    "print(f\"   Total: {len(dataset_base)} ejemplos en dataset_base.csv\")\n",
    "\n",
    "# Detectar columnas automÃ¡ticamente\n",
    "text_col = _guess_text_col(dataset_base)\n",
    "label_col = _guess_label_col(dataset_base)\n",
    "print(f\"\\nðŸ“‹ Columnas detectadas: texto='{text_col}', label='{label_col}'\")\n",
    "\n",
    "# Definir funciÃ³n de limpieza ligera\n",
    "_RE_MULTI = re.compile(r'(.)\\1{2,}')  # Detecta 3+ letras repetidas\n",
    "\n",
    "def clean_text_rb(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpieza LIGERA para rule-based (conserva estructura original).\n",
    "    \n",
    "    Aplica solo:\n",
    "    - NormalizaciÃ³n NFC (forma canÃ³nica de tildes)\n",
    "    - Colapso de alargamientos (holaaa â†’ holaa)\n",
    "    - NormalizaciÃ³n de espacios\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    \n",
    "    s = str(s).strip()\n",
    "    s = unicodedata.normalize(\"NFC\", s)  # Normaliza tildes (Ã© = Ã©, no e + Â´)\n",
    "    s = _RE_MULTI.sub(r'\\1\\1', s)        # holaaa â†’ holaa (mantiene Ã©nfasis)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()   # Colapsa espacios mÃºltiples\n",
    "    \n",
    "    return s\n",
    "\n",
    "# Aplicar limpieza ligera\n",
    "dataset_base['texto_rb'] = dataset_base[text_col].map(clean_text_rb)\n",
    "\n",
    "print(f\"\\nðŸ§¹ Aplicado preprocesamiento ligero (conserva tildes/mayÃºsculas)\")\n",
    "print(f\"   Ejemplo antes: {dataset_base[text_col].iloc[0][:80]}...\")\n",
    "print(f\"   Ejemplo despuÃ©s: {dataset_base['texto_rb'].iloc[0][:80]}...\")\n",
    "\n",
    "# Separar train y val usando Ã­ndices guardados\n",
    "df_train = dataset_base[dataset_base['row_id'].isin(train_indices)].copy()\n",
    "df_val = dataset_base[dataset_base['row_id'].isin(val_indices)].copy()\n",
    "\n",
    "print(f\"\\nðŸ“Š Splits creados:\")\n",
    "print(f\"\\nTrain ({len(df_train)} ejemplos):\")\n",
    "train_dist = df_train[label_col].value_counts()\n",
    "for label, count in train_dist.items():\n",
    "    print(f\"   {label}: {count}\")\n",
    "\n",
    "print(f\"\\nVal ({len(df_val)} ejemplos):\")\n",
    "val_dist = df_val[label_col].value_counts()\n",
    "for label, count in val_dist.items():\n",
    "    print(f\"   {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60611719",
   "metadata": {},
   "source": [
    "## 2) Ejecutar fork (perfil `col`) con solo Ansiedad/DepresiÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b09ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: /opt/anaconda3/bin/python /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY/cli.py --profile col --config /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY/configs/col_config.yml --input /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/ips_clean_tmp.csv --output /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv\n",
      "Components in NLP pipeline:\n",
      "\t- tok2vec\n",
      "\t- morphologizer\n",
      "\t- attribute_ruler\n",
      "\t- lemmatizer\n",
      "\t- medspacy_pyrush\n",
      "\t- medspacy_target_matcher\n",
      "\t- medspacy_context\n",
      "Concepts included (by folder): Ansiedad, Depresion\n",
      "Rule categories loaded: Abulia, Abusodesustancias, Agitacinpsicomotora, Alteracindelapercepcindepesoofiguracorporal, AngustiaMiedoTemor, Anhedonia, Animodeprimido, Animoexpansivo, Ansiedad, Apata, Apetitoaumentode, Apetitodisminucinde, Autolesin, Bajaconcentracin, Bajaenerga, Culpa, Desesperanza, Efectosadversos, Fatiga, Ideacinsuicida, Ideasdemuerte, Intentosuicida, Irritabilidad, Labilidademocional, Llantofcil, Malahigienepersonal, Negativismo, RetraimientosocialAislamiento, Retrasopsicomotor, Sntomasafectivos, Sntomasansiososgenerales, Sntomasdepresivosgenerales, SntomassomticosEjemplos\n",
      "Total target rules added: 229\n",
      "âœ… Guardado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv  | filas=626\n",
      "\n",
      "Components in NLP pipeline:\n",
      "\t- tok2vec\n",
      "\t- morphologizer\n",
      "\t- attribute_ruler\n",
      "\t- lemmatizer\n",
      "\t- medspacy_pyrush\n",
      "\t- medspacy_target_matcher\n",
      "\t- medspacy_context\n",
      "Concepts included (by folder): Ansiedad, Depresion\n",
      "Rule categories loaded: Abulia, Abusodesustancias, Agitacinpsicomotora, Alteracindelapercepcindepesoofiguracorporal, AngustiaMiedoTemor, Anhedonia, Animodeprimido, Animoexpansivo, Ansiedad, Apata, Apetitoaumentode, Apetitodisminucinde, Autolesin, Bajaconcentracin, Bajaenerga, Culpa, Desesperanza, Efectosadversos, Fatiga, Ideacinsuicida, Ideasdemuerte, Intentosuicida, Irritabilidad, Labilidademocional, Llantofcil, Malahigienepersonal, Negativismo, RetraimientosocialAislamiento, Retrasopsicomotor, Sntomasafectivos, Sntomasansiososgenerales, Sntomasdepresivosgenerales, SntomassomticosEjemplos\n",
      "Total target rules added: 229\n",
      "âœ… Guardado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv  | filas=626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, yaml\n",
    "from pathlib import Path\n",
    "\n",
    "cfg_dir = FORK_PATH/'configs'\n",
    "cfg_dir.mkdir(parents=True, exist_ok=True)\n",
    "col_cfg = cfg_dir/'col_config.yml'\n",
    "fenos_yml = cfg_dir/'fenotipos.yml'\n",
    "\n",
    "# Forzar solo Ansiedad/Depresion en el fork\n",
    "cfg = {}\n",
    "if col_cfg.exists():\n",
    "    cfg = yaml.safe_load(col_cfg.read_text(encoding='utf-8')) or {}\n",
    "cfg['text_column'] = 'texto_rb'\n",
    "col_cfg.write_text(yaml.safe_dump(cfg, allow_unicode=True), encoding='utf-8')\n",
    "\n",
    "fen = {}\n",
    "if fenos_yml.exists():\n",
    "    fen = yaml.safe_load(fenos_yml.read_text(encoding='utf-8')) or {}\n",
    "fen['active_concepts'] = ['Ansiedad','Depresion']\n",
    "fenos_yml.write_text(yaml.safe_dump(fen, allow_unicode=True), encoding='utf-8')\n",
    "\n",
    "cli_py = FORK_PATH/'cli.py'\n",
    "main_py = FORK_PATH/'main.py'\n",
    "runner = cli_py if cli_py.exists() else main_py\n",
    "assert runner.exists(), \"No se encontrÃ³ cli.py ni main.py en el fork.\"\n",
    "\n",
    "# Crear temp input solo con val set (para evaluar)\n",
    "tmp_in = DATA_PATH/'ips_clean_tmp.csv'\n",
    "df_val[['texto_rb', label_col]].rename(columns={'texto_rb':'texto_rb'}).to_csv(tmp_in, index=False, encoding='utf-8')\n",
    "\n",
    "# Salidas estandarizadas (comparables)\n",
    "rule_pred_csv   = DATA_PATH/'rule_based_predictions.csv'\n",
    "rule_report_csv = DATA_PATH/'rule_based_classification_report.csv'\n",
    "rule_eval_csv   = DATA_PATH/'rule_based_eval.csv'\n",
    "rule_cm_csv     = DATA_PATH/'rule_based_confusion_matrix.csv'\n",
    "\n",
    "cmd = [sys.executable, str(runner), '--profile','col', '--config', str(col_cfg),\n",
    "       '--input', str(tmp_in), '--output', str(rule_pred_csv)]\n",
    "print(\"CMD:\", \" \".join(map(str,cmd)))\n",
    "ret = subprocess.run(cmd, check=False, capture_output=True, text=True)\n",
    "print(ret.stdout)\n",
    "if ret.returncode != 0:\n",
    "    print(ret.stderr)\n",
    "    raise RuntimeError(f\"CLI terminÃ³ con cÃ³digo {ret.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb66af",
   "metadata": {},
   "source": [
    "## 3) EvaluaciÃ³n **binaria** y exportables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84dbc18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Exportados:\n",
      " - Predicciones: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv\n",
      " - Reporte: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_classification_report.csv\n",
      " - MÃ©tricas: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_eval.csv\n",
      " - Matriz: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_confusion_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, unicodedata as _ud\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "preds = pd.read_csv(rule_pred_csv)\n",
    "if 'pred_label' not in preds.columns:\n",
    "    raise ValueError(\"El output del fork no contiene 'pred_label'.\")\n",
    "\n",
    "def _norm_txt(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = _ud.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    return s\n",
    "\n",
    "y_pred = preds['pred_label'].map(_norm_txt)\n",
    "y_true = df_val[label_col].map(_norm_txt)\n",
    "\n",
    "# En caso de que el fork devuelva algo fuera de A/D, lo mapeamos a la clase mayoritaria para evaluar binario\n",
    "allowed = {'ansiedad','depresion'}\n",
    "majority = y_true.value_counts().idxmax()\n",
    "y_pred = y_pred.where(y_pred.isin(allowed), majority)\n",
    "\n",
    "classes = ['depresion','ansiedad']\n",
    "\n",
    "pd.DataFrame(classification_report(y_true, y_pred, labels=classes, output_dict=True, zero_division=0)).transpose()  .to_csv(rule_report_csv, index=True, encoding='utf-8')\n",
    "\n",
    "pd.DataFrame([{\n",
    "    'macro_f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'macro_precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'macro_recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'n': int(len(y_true))\n",
    "}]).to_csv(rule_eval_csv, index=False, encoding='utf-8')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "pd.DataFrame(cm, index=[f'true_{c}' for c in classes], columns=[f'pred_{c}' for c in classes]).to_csv(rule_cm_csv)\n",
    "\n",
    "print(\"âœ… Exportados:\")\n",
    "print(\" - Predicciones:\", rule_pred_csv)\n",
    "print(\" - Reporte:\", rule_report_csv)\n",
    "print(\" - MÃ©tricas:\", rule_eval_csv)\n",
    "print(\" - Matriz:\", rule_cm_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
