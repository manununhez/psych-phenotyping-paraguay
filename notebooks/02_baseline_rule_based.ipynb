{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc45479",
   "metadata": {},
   "source": [
    "# 02_baseline_rule_based — Binario A/D\n",
    "\n",
    "**Objetivo:** baseline **rule-based** usando el fork del proyecto colombiano (solo **Ansiedad/Depresión**) para obtener una primera línea de referencia.  \n",
    "**Justificación:** las reglas permiten:\n",
    "- establecer un punto de partida interpretable (trazabilidad por JSON/patrones),\n",
    "- detectar fallos sistemáticos del dataset (typos, negación, expresiones locales),\n",
    "- guiar el diseño del *cleaning* y la selección de fenotipos relevantes para A/D.\n",
    "\n",
    "> Nota: mantenemos **preprocesamiento ligero** para no romper *ConText* ni *TargetMatcher*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c9b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Utilizando utils_shared.py\n",
      "[INFO] Paths configurados:\n",
      "  BASE_PATH:   /Users/manuelnunez/Projects/psych-phenotyping-paraguay\n",
      "  DATA_PATH:   /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data\n",
      "  FORK_PATH:   /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY\n",
      "  SPLITS_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Setup: Paths, Imports, y Utilidades Compartidas\n",
    "# ===============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re, unicodedata, os\n",
    "\n",
    "# Intentar importar utilidades compartidas\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.insert(0, str(Path.cwd().parent))\n",
    "    from utils_shared import setup_paths, guess_text_col, guess_label_col, normalize_label\n",
    "    print(\"[INFO] Utilizando utils_shared.py\")\n",
    "    \n",
    "    # Setup de paths centralizado\n",
    "    paths = setup_paths()\n",
    "    BASE_PATH = paths['BASE_PATH']\n",
    "    DATA_PATH = paths['DATA_PATH']\n",
    "    FORK_PATH = paths['FORK_PATH']\n",
    "    SPLITS_PATH = paths['SPLITS_PATH']\n",
    "    \n",
    "    # Usar funciones centralizadas\n",
    "    _guess_text_col = guess_text_col\n",
    "    _guess_label_col = guess_label_col\n",
    "    _norm_label_bin = normalize_label\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"[WARNING] utils_shared.py no encontrado, usando funciones locales\")\n",
    "    \n",
    "    # Setup manual de paths\n",
    "    BASE_PATH = Path.cwd()\n",
    "    if BASE_PATH.name == \"notebooks\":\n",
    "        BASE_PATH = BASE_PATH.parent\n",
    "    \n",
    "    DATA_PATH = BASE_PATH / \"data\"\n",
    "    FORK_PATH = BASE_PATH / \"Spanish_Psych_Phenotyping_PY\"\n",
    "    SPLITS_PATH = DATA_PATH / \"splits\"\n",
    "    \n",
    "    DATA_PATH.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Funciones helper locales\n",
    "    def _guess_text_col(df):\n",
    "        for c in [\"texto\", \"text\", \"comment\", \"comentario\"]:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return df.columns[0]\n",
    "    \n",
    "    def _guess_label_col(df):\n",
    "        for c in [\"etiqueta\", \"label\", \"category\"]:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "        return df.columns[1] if len(df.columns) > 1 else df.columns[-1]\n",
    "    \n",
    "    def _norm_label_bin(s):\n",
    "        if pd.isna(s): \n",
    "            return \"\"\n",
    "        s = str(s).strip().lower()\n",
    "        s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "        return {'depresivo': 'depresion'}.get(s, s)\n",
    "\n",
    "# Validar existencia de directorios críticos\n",
    "if not FORK_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"[ERROR] Fork no encontrado en {FORK_PATH}\\n\"\n",
    "        f\"        Este baseline requiere Spanish_Psych_Phenotyping_PY/\"\n",
    "    )\n",
    "\n",
    "if not SPLITS_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"[ERROR] Splits no encontrados en {SPLITS_PATH}\\n\"\n",
    "        f\"        Debes ejecutar primero: 02_create_splits.ipynb\"\n",
    "    )\n",
    "\n",
    "print(f\"[INFO] Paths configurados:\")\n",
    "print(f\"  BASE_PATH:   {BASE_PATH}\")\n",
    "print(f\"  DATA_PATH:   {DATA_PATH}\")\n",
    "print(f\"  FORK_PATH:   {FORK_PATH}\")\n",
    "print(f\"  SPLITS_PATH: {SPLITS_PATH}\")\n",
    "\n",
    "# Columnas esperadas en dataset_base.csv\n",
    "TEXT_COL = \"texto\"\n",
    "LABEL_COL = \"etiqueta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6150cec7",
   "metadata": {},
   "source": [
    "## 1) Carga y preprocesamiento **ligero** (conserva tildes y casing, colapsa alargamientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489012c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CARGA DE SPLITS (PATIENT-LEVEL)\n",
      "============================================================\n",
      "✓ Dataset base: 3155 casos\n",
      "✓ Train indices: 2509 casos\n",
      "✓ Val indices: 646 casos\n",
      "\n",
      "[INFO] Split aplicado (patient-level):\n",
      "  Train: 2509 casos\n",
      "  Val:   646 casos\n",
      "\n",
      "[INFO] Distribución train: {'depresion': 1745, 'ansiedad': 764}\n",
      "[INFO] Distribución val: {'depresion': 485, 'ansiedad': 161}\n",
      "\n",
      "  RECORDATORIO: Estos splits eliminan leakage (pacientes disjuntos)\n",
      "   Métricas serán más conservadoras pero generalizan mejor.\n",
      "\n",
      "[INFO] Split aplicado (patient-level):\n",
      "  Train: 2509 casos\n",
      "  Val:   646 casos\n",
      "\n",
      "[INFO] Distribución train: {'depresion': 1745, 'ansiedad': 764}\n",
      "[INFO] Distribución val: {'depresion': 485, 'ansiedad': 161}\n",
      "\n",
      "  RECORDATORIO: Estos splits eliminan leakage (pacientes disjuntos)\n",
      "   Métricas serán más conservadoras pero generalizan mejor.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# CARGA DE DATOS - PATIENT-LEVEL SPLIT (SIN LEAKAGE)\n",
    "# ===============================================================\n",
    "# IMPORTANTE: Este baseline usa splits generados por 02_create_splits.ipynb\n",
    "#\n",
    "# Estrategia de split:\n",
    "#   - Por PACIENTES (no por casos/consultas)\n",
    "#   - 72 pacientes train / 18 pacientes val\n",
    "#   - 0% overlap (sin data leakage)\n",
    "#\n",
    "# ¿Por qué patient-level?\n",
    "#   Dataset tiene estructura longitudinal: 90 pacientes × 35 consultas promedio\n",
    "#   Split por casos → 100% pacientes en train Y val (leakage total)\n",
    "#   Split por pacientes → 0% overlap (generaliza a pacientes nuevos)\n",
    "#\n",
    "# Ver detalles en: ESTRATEGIA_SPLIT_PACIENTES.md\n",
    "\n",
    "import pandas as pd, re, unicodedata\n",
    "\n",
    "# Cargar splits unificados desde 02_create_splits.ipynb\n",
    "print(\"=\"*60)\n",
    "print(\"CARGA DE SPLITS (PATIENT-LEVEL)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset_base = pd.read_csv(SPLITS_PATH / 'dataset_base.csv')\n",
    "train_indices = pd.read_csv(SPLITS_PATH / 'train_indices.csv')['row_id'].values\n",
    "val_indices = pd.read_csv(SPLITS_PATH / 'val_indices.csv')['row_id'].values\n",
    "\n",
    "print(f\"✓ Dataset base: {len(dataset_base)} casos\")\n",
    "print(f\"✓ Train indices: {len(train_indices)} casos\")\n",
    "print(f\"✓ Val indices: {len(val_indices)} casos\")\n",
    "\n",
    "text_col = _guess_text_col(dataset_base)\n",
    "label_col = _guess_label_col(dataset_base)\n",
    "\n",
    "# ===============================================================\n",
    "# PREPROCESAMIENTO LIGERO (conserva estructura para rule-based)\n",
    "# ===============================================================\n",
    "# Estrategia: Mínima normalización (preserva tildes, mayúsculas, puntuación)\n",
    "# - Los patrones JSON son case-sensitive y usan tildes\n",
    "# - Solo colapsa alargamientos para mantener matching\n",
    "# - Comparación: TF-IDF normaliza todo, BETO tokeniza, Rule-based conserva estructura\n",
    "\n",
    "_RE_MULTI = re.compile(r'(.)\\1{2,}')  # Detecta 3+ letras repetidas\n",
    "\n",
    "def clean_text_rb(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpieza LIGERA para rule-based (conserva estructura original).\n",
    "    \n",
    "    Aplica solo:\n",
    "    - Normalización NFC (forma canónica de tildes)\n",
    "    - Colapso de alargamientos (holaaa → holaa)\n",
    "    - Normalización de espacios\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    \n",
    "    s = str(s).strip()\n",
    "    s = unicodedata.normalize(\"NFC\", s)  # Normaliza tildes (é = é, no e + ´)\n",
    "    s = _RE_MULTI.sub(r'\\1\\1', s)        # holaaa → holaa (mantiene énfasis)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()   # Colapsa espacios múltiples\n",
    "    \n",
    "    return s\n",
    "\n",
    "dataset_base['texto_rb'] = dataset_base[text_col].map(clean_text_rb)\n",
    "\n",
    "# Filtrar por índices (patient-level split)\n",
    "df_train = dataset_base[dataset_base['row_id'].isin(train_indices)].copy()\n",
    "df_val = dataset_base[dataset_base['row_id'].isin(val_indices)].copy()\n",
    "\n",
    "print(f\"\\n[INFO] Split aplicado (patient-level):\")\n",
    "print(f\"  Train: {len(df_train)} casos\")\n",
    "print(f\"  Val:   {len(df_val)} casos\")\n",
    "print(f\"\\n[INFO] Distribución train: {dict(df_train[label_col].value_counts())}\")\n",
    "print(f\"[INFO] Distribución val: {dict(df_val[label_col].value_counts())}\")\n",
    "print(\"\\n  RECORDATORIO: Estos splits eliminan leakage (pacientes disjuntos)\")\n",
    "print(\"   Métricas serán más conservadoras pero generalizan mejor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60611719",
   "metadata": {},
   "source": [
    "## 2) Ejecutar fork (perfil `col`) con solo Ansiedad/Depresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b09ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: /opt/anaconda3/bin/python /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY/cli.py --profile col --config /Users/manuelnunez/Projects/psych-phenotyping-paraguay/Spanish_Psych_Phenotyping_PY/configs/col_config.yml --input /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/ips_clean_tmp.csv --output /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv\n",
      "Components in NLP pipeline:\n",
      "\t- tok2vec\n",
      "\t- morphologizer\n",
      "\t- attribute_ruler\n",
      "\t- lemmatizer\n",
      "\t- medspacy_pyrush\n",
      "\t- medspacy_target_matcher\n",
      "\t- medspacy_context\n",
      "Concepts included (by folder): Ansiedad, Depresion\n",
      "Rule categories loaded: Abulia, Agitacinpsicomotora, AngustiaMiedoTemor, Anhedonia, Animodeprimido, Ansiedad, Apata, Apetitoaumentode, Apetitodisminucinde, Autolesin, Bajaconcentracin, Bajaenerga, Compulsiones, Culpa, Desesperanza, DespersonalizacinDesrealizacin, Disforia, Fatiga, Hipotimia, Ideacinpersecutoria, Ideacinsuicida, Ideasdemuerte, Intentosuicida, Irritabilidad, Labilidademocional, Llantofcil, Obsesiones, Paranoia, PesoIncremento, PesoPrdida, Pnico, Prospeccindesesperanzada, RetraimientosocialAislamiento, Retrasopsicomotor, Rumiacin, Sntomasansiososgenerales, Sntomasdepresivosgenerales, SntomassomticosEjemplos, Soledad, SueoAlterado, SueoDespertartemprano, SueoHipersomnio, SueoInsomnio, SueoPesadillas\n",
      "Total target rules added: 422\n",
      "✅ Guardado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv  | filas=646\n",
      "\n",
      "Components in NLP pipeline:\n",
      "\t- tok2vec\n",
      "\t- morphologizer\n",
      "\t- attribute_ruler\n",
      "\t- lemmatizer\n",
      "\t- medspacy_pyrush\n",
      "\t- medspacy_target_matcher\n",
      "\t- medspacy_context\n",
      "Concepts included (by folder): Ansiedad, Depresion\n",
      "Rule categories loaded: Abulia, Agitacinpsicomotora, AngustiaMiedoTemor, Anhedonia, Animodeprimido, Ansiedad, Apata, Apetitoaumentode, Apetitodisminucinde, Autolesin, Bajaconcentracin, Bajaenerga, Compulsiones, Culpa, Desesperanza, DespersonalizacinDesrealizacin, Disforia, Fatiga, Hipotimia, Ideacinpersecutoria, Ideacinsuicida, Ideasdemuerte, Intentosuicida, Irritabilidad, Labilidademocional, Llantofcil, Obsesiones, Paranoia, PesoIncremento, PesoPrdida, Pnico, Prospeccindesesperanzada, RetraimientosocialAislamiento, Retrasopsicomotor, Rumiacin, Sntomasansiososgenerales, Sntomasdepresivosgenerales, SntomassomticosEjemplos, Soledad, SueoAlterado, SueoDespertartemprano, SueoHipersomnio, SueoInsomnio, SueoPesadillas\n",
      "Total target rules added: 422\n",
      "✅ Guardado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv  | filas=646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, yaml\n",
    "from pathlib import Path\n",
    "\n",
    "cfg_dir = FORK_PATH/'configs'\n",
    "cfg_dir.mkdir(parents=True, exist_ok=True)\n",
    "col_cfg = cfg_dir/'col_config.yml'\n",
    "fenos_yml = cfg_dir/'fenotipos.yml'\n",
    "\n",
    "# Forzar solo Ansiedad/Depresion en el fork\n",
    "cfg = {}\n",
    "if col_cfg.exists():\n",
    "    cfg = yaml.safe_load(col_cfg.read_text(encoding='utf-8')) or {}\n",
    "cfg['text_column'] = 'texto_rb'\n",
    "col_cfg.write_text(yaml.safe_dump(cfg, allow_unicode=True), encoding='utf-8')\n",
    "\n",
    "fen = {}\n",
    "if fenos_yml.exists():\n",
    "    fen = yaml.safe_load(fenos_yml.read_text(encoding='utf-8')) or {}\n",
    "fen['active_concepts'] = ['Ansiedad','Depresion']\n",
    "fenos_yml.write_text(yaml.safe_dump(fen, allow_unicode=True), encoding='utf-8')\n",
    "\n",
    "cli_py = FORK_PATH/'cli.py'\n",
    "main_py = FORK_PATH/'main.py'\n",
    "runner = cli_py if cli_py.exists() else main_py\n",
    "assert runner.exists(), \"No se encontró cli.py ni main.py en el fork.\"\n",
    "\n",
    "# Crear temp input solo con val set (para evaluar)\n",
    "tmp_in = DATA_PATH/'ips_clean_tmp.csv'\n",
    "df_val[['texto_rb', label_col]].rename(columns={'texto_rb':'texto_rb'}).to_csv(tmp_in, index=False, encoding='utf-8')\n",
    "\n",
    "# Salidas estandarizadas (comparables)\n",
    "rule_pred_csv   = DATA_PATH/'rule_based_predictions.csv'\n",
    "rule_report_csv = DATA_PATH/'rule_based_classification_report.csv'\n",
    "rule_eval_csv   = DATA_PATH/'rule_based_eval.csv'\n",
    "rule_cm_csv     = DATA_PATH/'rule_based_confusion_matrix.csv'\n",
    "\n",
    "cmd = [sys.executable, str(runner), '--profile','col', '--config', str(col_cfg),\n",
    "       '--input', str(tmp_in), '--output', str(rule_pred_csv)]\n",
    "print(\"CMD:\", \" \".join(map(str,cmd)))\n",
    "ret = subprocess.run(cmd, check=False, capture_output=True, text=True)\n",
    "print(ret.stdout)\n",
    "if ret.returncode != 0:\n",
    "    print(ret.stderr)\n",
    "    raise RuntimeError(f\"CLI terminó con código {ret.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb66af",
   "metadata": {},
   "source": [
    "## 3) Evaluación **binaria** y exportables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84dbc18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Exportados:\n",
      "  - Predicciones: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_predictions.csv\n",
      "  - Reporte: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_classification_report.csv\n",
      "  - Métricas: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_eval.csv\n",
      "  - Matriz: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/rule_based_confusion_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, unicodedata as _ud\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "preds = pd.read_csv(rule_pred_csv)\n",
    "if 'pred_label' not in preds.columns:\n",
    "    raise ValueError(\"El output del fork no contiene 'pred_label'.\")\n",
    "\n",
    "def _norm_txt(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = _ud.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    return s\n",
    "\n",
    "y_pred = preds['pred_label'].map(_norm_txt)\n",
    "y_true = df_val[label_col].map(_norm_txt)\n",
    "\n",
    "# En caso de que el fork devuelva algo fuera de A/D, lo mapeamos a la clase mayoritaria para evaluar binario\n",
    "allowed = {'ansiedad','depresion'}\n",
    "majority = y_true.value_counts().idxmax()\n",
    "y_pred = y_pred.where(y_pred.isin(allowed), majority)\n",
    "\n",
    "classes = ['depresion','ansiedad']\n",
    "\n",
    "pd.DataFrame(classification_report(y_true, y_pred, labels=classes, output_dict=True, zero_division=0)).transpose()  .to_csv(rule_report_csv, index=True, encoding='utf-8')\n",
    "\n",
    "pd.DataFrame([{\n",
    "    'macro_f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'macro_precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'macro_recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "    'n': int(len(y_true))\n",
    "}]).to_csv(rule_eval_csv, index=False, encoding='utf-8')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "pd.DataFrame(cm, index=[f'true_{c}' for c in classes], columns=[f'pred_{c}' for c in classes]).to_csv(rule_cm_csv)\n",
    "\n",
    "print(\"[INFO] Exportados:\")\n",
    "print(\"  - Predicciones:\", rule_pred_csv)\n",
    "print(\"  - Reporte:\", rule_report_csv)\n",
    "print(\"  - Métricas:\", rule_eval_csv)\n",
    "print(\"  - Matriz:\", rule_cm_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe5435",
   "metadata": {},
   "source": [
    "## 4) Análisis de Errores (FP/FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2da311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Análisis de errores exportado:\n",
      "  FP Depresión: 99 casos → rule_based_fp_depresion.csv\n",
      "  FN Depresión: 0 casos → rule_based_fn_depresion.csv\n",
      "  FP Ansiedad:  0 casos → rule_based_fp_ansiedad.csv\n",
      "  FN Ansiedad:  99 casos → rule_based_fn_ansiedad.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/25/fy01l91x3gj63g090ghxj7000000gn/T/ipykernel_1040/2687782774.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  fp_depresion = df_val[(y_true == 'ansiedad') & (y_pred == 'depresion')].copy()\n",
      "/var/folders/25/fy01l91x3gj63g090ghxj7000000gn/T/ipykernel_1040/2687782774.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  fn_depresion = df_val[(y_true == 'depresion') & (y_pred == 'ansiedad')].copy()\n",
      "/var/folders/25/fy01l91x3gj63g090ghxj7000000gn/T/ipykernel_1040/2687782774.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  fp_ansiedad = df_val[(y_true == 'depresion') & (y_pred == 'ansiedad')].copy()\n",
      "/var/folders/25/fy01l91x3gj63g090ghxj7000000gn/T/ipykernel_1040/2687782774.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  fn_ansiedad = df_val[(y_true == 'ansiedad') & (y_pred == 'depresion')].copy()\n"
     ]
    }
   ],
   "source": [
    "# Exportar errores para análisis cualitativo\n",
    "fp_depresion = df_val[(y_true == 'ansiedad') & (y_pred == 'depresion')].copy()\n",
    "fp_depresion['error_type'] = 'FP_depresion'\n",
    "\n",
    "fn_depresion = df_val[(y_true == 'depresion') & (y_pred == 'ansiedad')].copy()\n",
    "fn_depresion['error_type'] = 'FN_depresion'\n",
    "\n",
    "fp_ansiedad = df_val[(y_true == 'depresion') & (y_pred == 'ansiedad')].copy()\n",
    "fp_ansiedad['error_type'] = 'FP_ansiedad'\n",
    "\n",
    "fn_ansiedad = df_val[(y_true == 'ansiedad') & (y_pred == 'depresion')].copy()\n",
    "fn_ansiedad['error_type'] = 'FN_ansiedad'\n",
    "\n",
    "rule_fp_dep_csv = DATA_PATH / 'rule_based_fp_depresion.csv'\n",
    "rule_fn_dep_csv = DATA_PATH / 'rule_based_fn_depresion.csv'\n",
    "rule_fp_ans_csv = DATA_PATH / 'rule_based_fp_ansiedad.csv'\n",
    "rule_fn_ans_csv = DATA_PATH / 'rule_based_fn_ansiedad.csv'\n",
    "\n",
    "fp_depresion[['texto_rb', label_col, 'error_type']].to_csv(rule_fp_dep_csv, index=False, encoding='utf-8')\n",
    "fn_depresion[['texto_rb', label_col, 'error_type']].to_csv(rule_fn_dep_csv, index=False, encoding='utf-8')\n",
    "fp_ansiedad[['texto_rb', label_col, 'error_type']].to_csv(rule_fp_ans_csv, index=False, encoding='utf-8')\n",
    "fn_ansiedad[['texto_rb', label_col, 'error_type']].to_csv(rule_fn_ans_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"[INFO] Análisis de errores exportado:\")\n",
    "print(f\"  FP Depresión: {len(fp_depresion)} casos → {rule_fp_dep_csv.name}\")\n",
    "print(f\"  FN Depresión: {len(fn_depresion)} casos → {rule_fn_dep_csv.name}\")\n",
    "print(f\"  FP Ansiedad:  {len(fp_ansiedad)} casos → {rule_fp_ans_csv.name}\")\n",
    "print(f\"  FN Ansiedad:  {len(fn_ansiedad)} casos → {rule_fn_ans_csv.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
