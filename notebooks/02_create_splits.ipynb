{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee5c248",
   "metadata": {},
   "source": [
    "# 02_create_splits ‚Äî Split √∫nico reproducible para todos los baselines\n",
    "\n",
    "**Objetivo:** crear **una sola vez** los splits train/val estratificados y guardarlos en `data/splits/` para que **todos los baselines** (rule-based, TF-IDF, transformer) usen **exactamente los mismos ejemplos** y sean **comparables**.\n",
    "\n",
    "**Outputs:**\n",
    "- `data/splits/train_indices.csv` (√≠ndices para train)\n",
    "- `data/splits/val_indices.csv` (√≠ndices para val)\n",
    "- `data/splits/dataset_base.csv` (dataset normalizado base con √≠ndices)\n",
    "\n",
    "**Reproducibilidad:** `random_state=42` fijo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0786bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• INPUT_FILE: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/ips_clean.csv\n",
      "üìÅ SPLITS_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits\n"
     ]
    }
   ],
   "source": [
    "# === Paths / Globals ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_PATH = Path.cwd()\n",
    "if BASE_PATH.name == \"notebooks\":\n",
    "    BASE_PATH = BASE_PATH.parent\n",
    "\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "SPLITS_PATH = DATA_PATH / \"splits\"\n",
    "SPLITS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Priorizar ips_clean.csv (generado por 01_eda) sobre ips_raw.csv\n",
    "INPUT_FILE = DATA_PATH / 'ips_clean.csv'\n",
    "if not INPUT_FILE.exists():\n",
    "    INPUT_FILE = DATA_PATH / 'ips_raw.csv'\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ ips_clean.csv, usando ips_raw.csv\")\n",
    "    print(\"   Recomendaci√≥n: ejecutar 01_eda_understanding.ipynb primero\")\n",
    "    if not INPUT_FILE.exists():\n",
    "        raise FileNotFoundError(f\"No se encontr√≥ ni ips_clean.csv ni ips_raw.csv en {DATA_PATH}\")\n",
    "\n",
    "print(\"üì• INPUT_FILE:\", INPUT_FILE)\n",
    "print(\"üìÅ SPLITS_PATH:\", SPLITS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495930a",
   "metadata": {},
   "source": [
    "## 1) Carga y normalizaci√≥n base (sin preprocesamiento de texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa153f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset cargado: 3125 ejemplos\n",
      "Distribuci√≥n:\n",
      "etiqueta\n",
      "depresion    2200\n",
      "ansiedad      925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Columnas esperadas\n",
    "TEXT_COL = \"texto\"\n",
    "LABEL_COL = \"etiqueta\"\n",
    "\n",
    "def _guess_text_col(df):\n",
    "    if TEXT_COL in df.columns: \n",
    "        return TEXT_COL\n",
    "    for c in ['texto','Motivo Consulta','original_motivo_consulta','text']:\n",
    "        if c in df.columns: return c\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == 'O': return c\n",
    "    raise ValueError(\"No se encontr√≥ columna de texto.\")\n",
    "\n",
    "def _guess_label_col(df):\n",
    "    if LABEL_COL in df.columns: \n",
    "        return LABEL_COL\n",
    "    for c in ['etiqueta','Tipo','label','target','y','clase']:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "def _norm_label_bin(s):\n",
    "    \"\"\"Normaliza etiquetas a 'ansiedad' o 'depresion'\"\"\"\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    return {'depresivo':'depresion'}.get(s, s)\n",
    "\n",
    "# Cargar\n",
    "df_raw = pd.read_csv(INPUT_FILE)\n",
    "text_col = _guess_text_col(df_raw)\n",
    "label_col = _guess_label_col(df_raw)\n",
    "\n",
    "if label_col is None:\n",
    "    raise ValueError(\"Se requiere columna de etiquetas.\")\n",
    "\n",
    "# Filtrar y normalizar (si viene de ips_raw, ya deber√≠a estar limpio si viene de ips_clean)\n",
    "df = df_raw.dropna(subset=[text_col, label_col]).copy()\n",
    "df[label_col] = df[label_col].map(_norm_label_bin)\n",
    "df = df[df[label_col].isin(['ansiedad','depresion'])].copy()\n",
    "\n",
    "# Eliminar duplicados en texto (por si viene de ips_raw)\n",
    "n_before = len(df)\n",
    "df = df.drop_duplicates(subset=[text_col]).copy()\n",
    "n_after = len(df)\n",
    "if n_before > n_after:\n",
    "    print(f\"‚ö†Ô∏è Eliminados {n_before - n_after} duplicados (usar ips_clean.csv para evitar esto)\")\n",
    "\n",
    "# Resetear √≠ndice y crear ID √∫nico\n",
    "df = df.reset_index(drop=True)\n",
    "df['row_id'] = df.index\n",
    "\n",
    "print(f\"‚úÖ Dataset cargado: {len(df)} ejemplos\")\n",
    "print(f\"Distribuci√≥n:\\n{df[label_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2db3d",
   "metadata": {},
   "source": [
    "## 2) Split estratificado (80/20) con semilla fija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe464a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2500 | Val: 625\n",
      "Train distribuci√≥n:\n",
      "etiqueta\n",
      "depresion    1760\n",
      "ansiedad      740\n",
      "Name: count, dtype: int64\n",
      "Val distribuci√≥n:\n",
      "etiqueta\n",
      "depresion    440\n",
      "ansiedad     185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    df.index,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df[label_col]\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_idx)} | Val: {len(val_idx)}\")\n",
    "print(f\"Train distribuci√≥n:\\n{df.loc[train_idx, label_col].value_counts()}\")\n",
    "print(f\"Val distribuci√≥n:\\n{df.loc[val_idx, label_col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebec7ba",
   "metadata": {},
   "source": [
    "## 3) Guardar splits y dataset base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc033898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Archivos guardados:\n",
      " - /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits/train_indices.csv\n",
      " - /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits/val_indices.csv\n",
      " - /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits/dataset_base.csv\n",
      "\n",
      "üìä Origen: ips_clean.csv\n",
      "üîí Ahora todos los baselines deben usar estos splits.\n"
     ]
    }
   ],
   "source": [
    "# Guardar √≠ndices\n",
    "pd.DataFrame({'row_id': train_idx}).to_csv(SPLITS_PATH/'train_indices.csv', index=False)\n",
    "pd.DataFrame({'row_id': val_idx}).to_csv(SPLITS_PATH/'val_indices.csv', index=False)\n",
    "\n",
    "# Guardar dataset base (con texto original y etiqueta normalizada)\n",
    "df_base = df[['row_id', text_col, label_col]].copy()\n",
    "df_base.to_csv(SPLITS_PATH/'dataset_base.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"\\n‚úÖ Archivos guardados:\")\n",
    "print(f\" - {SPLITS_PATH/'train_indices.csv'}\")\n",
    "print(f\" - {SPLITS_PATH/'val_indices.csv'}\")\n",
    "print(f\" - {SPLITS_PATH/'dataset_base.csv'}\")\n",
    "print(f\"\\nüìä Origen: {INPUT_FILE.name}\")\n",
    "print(f\"üîí Ahora todos los baselines deben usar estos splits.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
