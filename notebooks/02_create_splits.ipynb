{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a698fd",
   "metadata": {},
   "source": [
    "# Creación de Splits (Patient-Level - SIN DATA LEAKAGE)\n",
    "\n",
    "**Versión corregida:** Split por PACIENTES (no por casos)\n",
    "\n",
    "**Problema anterior:**\n",
    "- Split por casos → Mismo paciente en train Y val\n",
    "- 90 pacientes con 35 consultas promedio c/u\n",
    "- 100% leakage (modelo memoriza pacientes)\n",
    "\n",
    "**Solución:**\n",
    "- Split por Prontuario (patient ID)\n",
    "- 72 pacientes train (80%) / 18 pacientes val (20%)\n",
    "- 0% leakage (pacientes disjuntos)\n",
    "\n",
    "**Estratificación:**\n",
    "- Estratificar por CLASE MAYORITARIA del paciente\n",
    "- Si paciente tiene 10 consultas ansiedad + 2 depresión → etiqueta = ansiedad\n",
    "- Garantiza distribución similar en train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77559f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 42\n",
      "Test size: 0.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Configuración\n",
    "DATA_PATH = Path('../data')\n",
    "SPLITS_PATH = DATA_PATH / 'splits'\n",
    "SPLITS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "PATIENT_COL = 'Prontuario'\n",
    "LABEL_COL = 'Tipo'\n",
    "TEXT_COL = 'Motivo Consulta'\n",
    "\n",
    "print(f\"Random state: {RANDOM_STATE}\")\n",
    "print(f\"Test size: {TEST_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da701d9b",
   "metadata": {},
   "source": [
    "## 1. Cargar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab455c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: ../data/ips_raw.csv\n",
      "Total casos: 3155\n",
      "Columnas: ['Archivo', 'Prontuario', 'Nombre Paciente', 'Sexo', 'Fecha Nacimiento', 'N° Consulta', 'Id', 'Fecha Consulta', 'Motivo Consulta', 'Tipo']\n",
      "\n",
      "Distribución clases:\n",
      "Tipo\n",
      "depresion    2230\n",
      "ansiedad      925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar ips_raw.csv\n",
    "INPUT_FILE = DATA_PATH / 'ips_raw.csv'\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "print(f\"Dataset cargado: {INPUT_FILE}\")\n",
    "print(f\"Total casos: {len(df)}\")\n",
    "print(f\"Columnas: {list(df.columns)}\")\n",
    "print(f\"\\nDistribución clases:\")\n",
    "print(df[LABEL_COL].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c391f0c",
   "metadata": {},
   "source": [
    "## 2. Análisis a nivel paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e81d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISIS A NIVEL PACIENTE\n",
      "============================================================\n",
      "Pacientes únicos: 90\n",
      "Casos totales: 3155\n",
      "Promedio casos/paciente: 35.06\n",
      "Mediana casos/paciente: 34\n",
      "Min-Max casos/paciente: 6-65\n",
      "\n",
      "Distribución casos/paciente:\n",
      "count    90.000000\n",
      "mean     35.055556\n",
      "std      11.647791\n",
      "min       6.000000\n",
      "25%      27.000000\n",
      "50%      33.500000\n",
      "75%      42.750000\n",
      "max      65.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Estadísticas por paciente\n",
    "n_patients = df[PATIENT_COL].nunique()\n",
    "n_cases = len(df)\n",
    "avg_cases = n_cases / n_patients\n",
    "\n",
    "patient_counts = df[PATIENT_COL].value_counts()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANÁLISIS A NIVEL PACIENTE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pacientes únicos: {n_patients}\")\n",
    "print(f\"Casos totales: {n_cases}\")\n",
    "print(f\"Promedio casos/paciente: {avg_cases:.2f}\")\n",
    "print(f\"Mediana casos/paciente: {patient_counts.median():.0f}\")\n",
    "print(f\"Min-Max casos/paciente: {patient_counts.min()}-{patient_counts.max()}\")\n",
    "\n",
    "# Distribución\n",
    "print(f\"\\nDistribución casos/paciente:\")\n",
    "print(patient_counts.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d45e2f",
   "metadata": {},
   "source": [
    "## 3. Asignar clase mayoritaria por paciente\n",
    "\n",
    "**Estrategia de estratificación:**\n",
    "- Cada paciente tiene etiqueta = clase con más consultas\n",
    "- Ejemplo: Paciente A con 8 consultas ansiedad + 2 depresión → etiqueta_paciente = 'ansiedad'\n",
    "- Esto permite estratificar el split de pacientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f5ad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de pacientes por clase mayoritaria:\n",
      "etiqueta_mayoritaria\n",
      "depresion    57\n",
      "ansiedad     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ratio ansiedad/depresión (pacientes): 0.58\n"
     ]
    }
   ],
   "source": [
    "def get_patient_majority_label(patient_id, df, label_col):\n",
    "    \"\"\"Obtiene la clase mayoritaria de un paciente\"\"\"\n",
    "    patient_labels = df[df[PATIENT_COL] == patient_id][label_col]\n",
    "    most_common = Counter(patient_labels).most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "# Crear DataFrame de pacientes con su clase mayoritaria\n",
    "patients = df[PATIENT_COL].unique()\n",
    "patient_labels = {p: get_patient_majority_label(p, df, LABEL_COL) for p in patients}\n",
    "\n",
    "patients_df = pd.DataFrame({\n",
    "    'Prontuario': list(patient_labels.keys()),\n",
    "    'etiqueta_mayoritaria': list(patient_labels.values())\n",
    "})\n",
    "\n",
    "print(\"Distribución de pacientes por clase mayoritaria:\")\n",
    "print(patients_df['etiqueta_mayoritaria'].value_counts())\n",
    "print(f\"\\nRatio ansiedad/depresión (pacientes): {patients_df['etiqueta_mayoritaria'].value_counts()['ansiedad'] / patients_df['etiqueta_mayoritaria'].value_counts()['depresion']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f76daf",
   "metadata": {},
   "source": [
    "## 4. Split por PACIENTES (estratificado)\n",
    "\n",
    "**CRÍTICO:** Dividir pacientes (no casos) para evitar data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4885fcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SPLIT POR PACIENTES (PATIENT-LEVEL)\n",
      "============================================================\n",
      "Pacientes en train: 72 (80.0%)\n",
      "Pacientes en val: 18 (20.0%)\n",
      "\n",
      "✓ Overlap: 0 pacientes (DEBE SER 0)\n"
     ]
    }
   ],
   "source": [
    "# Split de pacientes (80/20)\n",
    "train_patients, val_patients = train_test_split(\n",
    "    patients_df['Prontuario'],\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=patients_df['etiqueta_mayoritaria']  # Estratificar por clase mayoritaria\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SPLIT POR PACIENTES (PATIENT-LEVEL)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pacientes en train: {len(train_patients)} ({len(train_patients)/n_patients*100:.1f}%)\")\n",
    "print(f\"Pacientes en val: {len(val_patients)} ({len(val_patients)/n_patients*100:.1f}%)\")\n",
    "\n",
    "# Verificar no overlap\n",
    "overlap = set(train_patients) & set(val_patients)\n",
    "print(f\"\\n✓ Overlap: {len(overlap)} pacientes (DEBE SER 0)\")\n",
    "assert len(overlap) == 0, \"ERROR: Hay pacientes en train Y val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335cd99",
   "metadata": {},
   "source": [
    "## 5. Obtener índices de casos (train/val)\n",
    "\n",
    "Ahora convertimos pacientes → casos (consultas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64bb5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CASOS RESULTANTES\n",
      "============================================================\n",
      "Casos en train: 2509 (79.5%)\n",
      "Casos en val: 646 (20.5%)\n",
      "\n",
      "Distribución train:\n",
      "Tipo\n",
      "depresion    1745\n",
      "ansiedad      764\n",
      "Name: count, dtype: int64\n",
      "Ratio A/D: 0.44\n",
      "\n",
      "Distribución val:\n",
      "Tipo\n",
      "depresion    485\n",
      "ansiedad     161\n",
      "Name: count, dtype: int64\n",
      "Ratio A/D: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Filtrar casos por pacientes asignados\n",
    "train_mask = df[PATIENT_COL].isin(train_patients)\n",
    "val_mask = df[PATIENT_COL].isin(val_patients)\n",
    "\n",
    "train_idx = df[train_mask].index.tolist()\n",
    "val_idx = df[val_mask].index.tolist()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CASOS RESULTANTES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Casos en train: {len(train_idx)} ({len(train_idx)/n_cases*100:.1f}%)\")\n",
    "print(f\"Casos en val: {len(val_idx)} ({len(val_idx)/n_cases*100:.1f}%)\")\n",
    "\n",
    "# Distribución de clases en train/val\n",
    "train_labels = df.loc[train_idx, LABEL_COL]\n",
    "val_labels = df.loc[val_idx, LABEL_COL]\n",
    "\n",
    "print(f\"\\nDistribución train:\")\n",
    "print(train_labels.value_counts())\n",
    "print(f\"Ratio A/D: {train_labels.value_counts()['ansiedad'] / train_labels.value_counts()['depresion']:.2f}\")\n",
    "\n",
    "print(f\"\\nDistribución val:\")\n",
    "print(val_labels.value_counts())\n",
    "print(f\"Ratio A/D: {val_labels.value_counts()['ansiedad'] / val_labels.value_counts()['depresion']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fbe24",
   "metadata": {},
   "source": [
    "## 6. Verificación: No data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a9079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICACIÓN DATA LEAKAGE\n",
      "============================================================\n",
      "Pacientes únicos en train: 72\n",
      "Pacientes únicos en val: 18\n",
      "Pacientes en AMBOS: 0\n",
      "\n",
      "✅ VERIFICACIÓN EXITOSA: NO HAY DATA LEAKAGE\n"
     ]
    }
   ],
   "source": [
    "# Verificar que no hay pacientes compartidos\n",
    "train_patients_check = set(df.loc[train_idx, PATIENT_COL])\n",
    "val_patients_check = set(df.loc[val_idx, PATIENT_COL])\n",
    "overlap_check = train_patients_check & val_patients_check\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICACIÓN DATA LEAKAGE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pacientes únicos en train: {len(train_patients_check)}\")\n",
    "print(f\"Pacientes únicos en val: {len(val_patients_check)}\")\n",
    "print(f\"Pacientes en AMBOS: {len(overlap_check)}\")\n",
    "\n",
    "if len(overlap_check) == 0:\n",
    "    print(\"\\n✅ VERIFICACIÓN EXITOSA: NO HAY DATA LEAKAGE\")\n",
    "else:\n",
    "    print(f\"\\n❌ ERROR: {len(overlap_check)} pacientes en train Y val\")\n",
    "    print(f\"Pacientes con leakage: {list(overlap_check)[:5]}\")\n",
    "    raise ValueError(\"DATA LEAKAGE DETECTADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349050d3",
   "metadata": {},
   "source": [
    "## 7. Guardar splits\n",
    "\n",
    "**IMPORTANTE:** Crear `row_id` único para cada caso (necesario para merge en baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "540f3175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ARCHIVOS GUARDADOS\n",
      "============================================================\n",
      "Ubicación: ../data/splits/\n",
      "\n",
      "1. dataset_base.csv\n",
      "   - 3155 casos\n",
      "   - Columnas: row_id, patient_id, texto, etiqueta\n",
      "\n",
      "2. train_indices.csv\n",
      "   - 2509 índices (de 72 pacientes)\n",
      "\n",
      "3. val_indices.csv\n",
      "   - 646 índices (de 18 pacientes)\n"
     ]
    }
   ],
   "source": [
    "# Asignar row_id como índice original\n",
    "df['row_id'] = df.index\n",
    "\n",
    "# Preparar dataset base\n",
    "df_base = df[['row_id', PATIENT_COL, TEXT_COL, LABEL_COL]].copy()\n",
    "df_base.columns = ['row_id', 'patient_id', 'texto', 'etiqueta']\n",
    "\n",
    "# Normalizar etiquetas\n",
    "label_map = {'depresivo': 'depresion'}  # Mapeo si hay variantes\n",
    "df_base['etiqueta'] = df_base['etiqueta'].str.lower().map(lambda x: label_map.get(x, x))\n",
    "\n",
    "# Guardar archivos\n",
    "dataset_base_path = SPLITS_PATH / 'dataset_base.csv'\n",
    "train_indices_path = SPLITS_PATH / 'train_indices.csv'\n",
    "val_indices_path = SPLITS_PATH / 'val_indices.csv'\n",
    "\n",
    "df_base.to_csv(dataset_base_path, index=False, encoding='utf-8')\n",
    "pd.DataFrame({'row_id': train_idx}).to_csv(train_indices_path, index=False)\n",
    "pd.DataFrame({'row_id': val_idx}).to_csv(val_indices_path, index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHIVOS GUARDADOS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Ubicación: {SPLITS_PATH}/\")\n",
    "print(f\"\\n1. dataset_base.csv\")\n",
    "print(f\"   - {len(df_base)} casos\")\n",
    "print(f\"   - Columnas: row_id, patient_id, texto, etiqueta\")\n",
    "print(f\"\\n2. train_indices.csv\")\n",
    "print(f\"   - {len(train_idx)} índices (de {len(train_patients)} pacientes)\")\n",
    "print(f\"\\n3. val_indices.csv\")\n",
    "print(f\"   - {len(val_idx)} índices (de {len(val_patients)} pacientes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f137dc",
   "metadata": {},
   "source": [
    "## 8. Reporte final y comparación\n",
    "\n",
    "Comparar distribución antes/después de split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d5a256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESUMEN: SPLIT POR PACIENTES (SIN LEAKAGE)\n",
      "============================================================\n",
      "\n",
      "DATASET COMPLETO:\n",
      "  - 90 pacientes\n",
      "  - 3155 casos (consultas)\n",
      "  - 35.1 casos/paciente promedio\n",
      "\n",
      "SPLIT REALIZADO:\n",
      "  - Train: 72 pacientes (2509 casos)\n",
      "  - Val:   18 pacientes (646 casos)\n",
      "  - Ratio train/val: 4.0\n",
      "\n",
      "VERIFICACIÓN:\n",
      "  - Pacientes compartidos: 0 (0 = correcto)\n",
      "  - Estratificación por clase mayoritaria: ✓\n",
      "  - Random seed fijo: 42 (reproducible)\n",
      "\n",
      "CAMBIO vs SPLIT ANTERIOR (por casos):\n",
      "  - Antes: 100% pacientes en train Y val (leakage total)\n",
      "  - Ahora: 0% pacientes compartidos (sin leakage)\n",
      "  - Impacto esperado: F1 score bajará 3-5% (métricas reales)\n",
      "\n",
      "ARCHIVOS PARA BASELINES:\n",
      "  1. Cargar dataset_base.csv\n",
      "  2. Cargar train_indices.csv y val_indices.csv\n",
      "  3. Filtrar usando row_id\n",
      "  4. RE-ENTRENAR TODOS LOS BASELINES con nuevos splits\n",
      "\n",
      "============================================================\n",
      "IMPORTANTE: Este split DEBE ser usado por TODOS los baselines\n",
      "para garantizar comparación justa y métricas válidas\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN: SPLIT POR PACIENTES (SIN LEAKAGE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDATASET COMPLETO:\")\n",
    "print(f\"  - {n_patients} pacientes\")\n",
    "print(f\"  - {n_cases} casos (consultas)\")\n",
    "print(f\"  - {avg_cases:.1f} casos/paciente promedio\")\n",
    "\n",
    "print(f\"\\nSPLIT REALIZADO:\")\n",
    "print(f\"  - Train: {len(train_patients)} pacientes ({len(train_idx)} casos)\")\n",
    "print(f\"  - Val:   {len(val_patients)} pacientes ({len(val_idx)} casos)\")\n",
    "print(f\"  - Ratio train/val: {len(train_patients)/len(val_patients):.1f}\")\n",
    "\n",
    "print(f\"\\nVERIFICACIÓN:\")\n",
    "print(f\"  - Pacientes compartidos: {len(overlap_check)} (0 = correcto)\")\n",
    "print(f\"  - Estratificación por clase mayoritaria: ✓\")\n",
    "print(f\"  - Random seed fijo: {RANDOM_STATE} (reproducible)\")\n",
    "\n",
    "print(f\"\\nCAMBIO vs SPLIT ANTERIOR (por casos):\")\n",
    "print(f\"  - Antes: 100% pacientes en train Y val (leakage total)\")\n",
    "print(f\"  - Ahora: 0% pacientes compartidos (sin leakage)\")\n",
    "print(f\"  - Impacto esperado: F1 score bajará 3-5% (métricas reales)\")\n",
    "\n",
    "print(f\"\\nARCHIVOS PARA BASELINES:\")\n",
    "print(f\"  1. Cargar {dataset_base_path.name}\")\n",
    "print(f\"  2. Cargar {train_indices_path.name} y {val_indices_path.name}\")\n",
    "print(f\"  3. Filtrar usando row_id\")\n",
    "print(f\"  4. RE-ENTRENAR TODOS LOS BASELINES con nuevos splits\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPORTANTE: Este split DEBE ser usado por TODOS los baselines\")\n",
    "print(\"para garantizar comparación justa y métricas válidas\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
