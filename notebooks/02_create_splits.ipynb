{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a698fd",
   "metadata": {},
   "source": [
    "# Creación de Splits (Patient-Level - SIN DATA LEAKAGE)\n",
    "\n",
    "**Split de 3 vías:** Train (60%) / Dev (20%) / Test (20%)\n",
    "\n",
    "**Problema anterior:**\n",
    "- Split por casos → Mismo paciente en train Y val\n",
    "- 90 pacientes con 35 consultas promedio c/u\n",
    "- 100% leakage (modelo memoriza pacientes)\n",
    "\n",
    "**Solución:**\n",
    "- Split por Prontuario (patient ID)\n",
    "- 54 pacientes train (60%) / 18 pacientes dev (20%) / 18 pacientes test (20%)\n",
    "- 0% leakage (pacientes disjuntos entre los 3 conjuntos)\n",
    "\n",
    "**Estratificación:**\n",
    "- Estratificar por CLASE MAYORITARIA del paciente\n",
    "- Si paciente tiene 10 consultas ansiedad + 2 depresión → etiqueta = ansiedad\n",
    "- Garantiza distribución similar en train/dev/test\n",
    "\n",
    "**Justificación del split de 3 vías:**\n",
    "- **Train (60%)**: Análisis exploratorio y desarrollo de Concept_PY\n",
    "- **Dev (20%)**: Iteración y refinamiento (puede mirarse múltiples veces)\n",
    "- **Test (20%)**: Evaluación final CIEGA (solo una vez al final)\n",
    "- Evita overfitting indirecto al desarrollar reglas basadas en conocimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77559f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 42\n",
      "Split ratio: Train 60% / Dev 20% / Test 20%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Configuración\n",
    "DATA_PATH = Path('../data')\n",
    "SPLITS_PATH = DATA_PATH / 'splits'\n",
    "SPLITS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "DEV_SIZE = 0.2   # 20% para dev\n",
    "TEST_SIZE = 0.2  # 20% para test\n",
    "# Train será el restante: 1 - 0.2 - 0.2 = 60%\n",
    "\n",
    "# Columnas de ips_clean.csv\n",
    "PATIENT_COL = 'id_paciente'\n",
    "LABEL_COL = 'etiqueta'\n",
    "TEXT_COL = 'texto'\n",
    "\n",
    "print(f\"Random state: {RANDOM_STATE}\")\n",
    "print(f\"Split ratio: Train 60% / Dev 20% / Test 20%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da701d9b",
   "metadata": {},
   "source": [
    "## 1. Cargar dataset\n",
    "\n",
    "**IMPORTANTE:** Usar `ips_clean.csv` (3,127 casos) generado por `01_eda_understanding.ipynb`\n",
    "- Dataset limpio con remoción de 43,938 oraciones duplicadas\n",
    "- Garantiza comparación justa con baselines anteriores (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab455c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: ../data/ips_clean.csv\n",
      "Total casos: 3127\n",
      "Columnas: ['id_paciente', 'fecha', 'etiqueta', 'texto']\n",
      "\n",
      "Distribución clases:\n",
      "etiqueta\n",
      "depresion    2202\n",
      "ansiedad      925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar ips_clean.csv (dataset limpio sin duplicados)\n",
    "INPUT_FILE = DATA_PATH / 'ips_clean.csv'\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "print(f\"Dataset cargado: {INPUT_FILE}\")\n",
    "print(f\"Total casos: {len(df)}\")\n",
    "print(f\"Columnas: {list(df.columns)}\")\n",
    "print(f\"\\nDistribución clases:\")\n",
    "print(df[LABEL_COL].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c391f0c",
   "metadata": {},
   "source": [
    "## 2. Análisis a nivel paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e81d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISIS A NIVEL PACIENTE\n",
      "============================================================\n",
      "Pacientes únicos: 90\n",
      "Casos totales: 3127\n",
      "Promedio casos/paciente: 34.74\n",
      "Mediana casos/paciente: 33\n",
      "Min-Max casos/paciente: 6-63\n",
      "\n",
      "Distribución casos/paciente:\n",
      "count    90.000000\n",
      "mean     34.744444\n",
      "std      11.404278\n",
      "min       6.000000\n",
      "25%      27.000000\n",
      "50%      33.000000\n",
      "75%      42.000000\n",
      "max      63.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Estadísticas por paciente\n",
    "n_patients = df[PATIENT_COL].nunique()\n",
    "n_cases = len(df)\n",
    "avg_cases = n_cases / n_patients\n",
    "\n",
    "patient_counts = df[PATIENT_COL].value_counts()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANÁLISIS A NIVEL PACIENTE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pacientes únicos: {n_patients}\")\n",
    "print(f\"Casos totales: {n_cases}\")\n",
    "print(f\"Promedio casos/paciente: {avg_cases:.2f}\")\n",
    "print(f\"Mediana casos/paciente: {patient_counts.median():.0f}\")\n",
    "print(f\"Min-Max casos/paciente: {patient_counts.min()}-{patient_counts.max()}\")\n",
    "\n",
    "# Distribución\n",
    "print(f\"\\nDistribución casos/paciente:\")\n",
    "print(patient_counts.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d45e2f",
   "metadata": {},
   "source": [
    "## 3. Asignar clase mayoritaria por paciente\n",
    "\n",
    "**Estrategia de estratificación:**\n",
    "- Cada paciente tiene etiqueta = clase con más consultas\n",
    "- Ejemplo: Paciente A con 8 consultas ansiedad + 2 depresión → etiqueta_paciente = 'ansiedad'\n",
    "- Esto permite estratificar el split de pacientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25f5ad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de pacientes por clase mayoritaria:\n",
      "etiqueta_mayoritaria\n",
      "depresion    57\n",
      "ansiedad     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ratio ansiedad/depresión (pacientes): 0.58\n"
     ]
    }
   ],
   "source": [
    "def get_patient_majority_label(patient_id, df, label_col):\n",
    "    \"\"\"Obtiene la clase mayoritaria de un paciente\"\"\"\n",
    "    patient_labels = df[df[PATIENT_COL] == patient_id][label_col]\n",
    "    most_common = Counter(patient_labels).most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "# Crear DataFrame de pacientes con su clase mayoritaria\n",
    "patients = df[PATIENT_COL].unique()\n",
    "patient_labels = {p: get_patient_majority_label(p, df, LABEL_COL) for p in patients}\n",
    "\n",
    "patients_df = pd.DataFrame({\n",
    "    'Prontuario': list(patient_labels.keys()),\n",
    "    'etiqueta_mayoritaria': list(patient_labels.values())\n",
    "})\n",
    "\n",
    "print(\"Distribución de pacientes por clase mayoritaria:\")\n",
    "print(patients_df['etiqueta_mayoritaria'].value_counts())\n",
    "print(f\"\\nRatio ansiedad/depresión (pacientes): {patients_df['etiqueta_mayoritaria'].value_counts()['ansiedad'] / patients_df['etiqueta_mayoritaria'].value_counts()['depresion']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f76daf",
   "metadata": {},
   "source": [
    "## 4. Split por PACIENTES en 3 conjuntos (estratificado)\n",
    "\n",
    "**CRÍTICO:** Dividir pacientes (no casos) para evitar data leakage\n",
    "\n",
    "**Estrategia:**\n",
    "1. Primero: separar test (20%) del total\n",
    "2. Segundo: del restante (80%), separar train (75% de 80% = 60% total) y dev (25% de 80% = 20% total)\n",
    "3. Resultado: Train 60% / Dev 20% / Test 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4885fcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SPLIT POR PACIENTES (PATIENT-LEVEL) - 3 CONJUNTOS\n",
      "============================================================\n",
      "Pacientes en train: 54 (60.0%)\n",
      "Pacientes en dev:   18 (20.0%)\n",
      "Pacientes en test:  18 (20.0%)\n",
      "\n",
      "✓ Overlap train-dev: 0 pacientes (DEBE SER 0)\n",
      "✓ Overlap train-test: 0 pacientes (DEBE SER 0)\n",
      "✓ Overlap dev-test: 0 pacientes (DEBE SER 0)\n"
     ]
    }
   ],
   "source": [
    "# Split de pacientes en 3 conjuntos (60/20/20)\n",
    "\n",
    "# Paso 1: Separar test set (20%) del total\n",
    "train_dev_patients, test_patients = train_test_split(\n",
    "    patients_df['Prontuario'],\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=patients_df['etiqueta_mayoritaria']\n",
    ")\n",
    "\n",
    "# Paso 2: Del restante (80%), separar train (75%) y dev (25%)\n",
    "# 75% de 80% = 60% del total\n",
    "# 25% de 80% = 20% del total\n",
    "train_patients, dev_patients = train_test_split(\n",
    "    train_dev_patients,\n",
    "    test_size=0.25,  # 25% del 80% = 20% del total\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=patients_df[patients_df['Prontuario'].isin(train_dev_patients)]['etiqueta_mayoritaria']\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SPLIT POR PACIENTES (PATIENT-LEVEL) - 3 CONJUNTOS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pacientes en train: {len(train_patients)} ({len(train_patients)/n_patients*100:.1f}%)\")\n",
    "print(f\"Pacientes en dev:   {len(dev_patients)} ({len(dev_patients)/n_patients*100:.1f}%)\")\n",
    "print(f\"Pacientes en test:  {len(test_patients)} ({len(test_patients)/n_patients*100:.1f}%)\")\n",
    "\n",
    "# Verificar no overlap\n",
    "overlap_train_dev = set(train_patients) & set(dev_patients)\n",
    "overlap_train_test = set(train_patients) & set(test_patients)\n",
    "overlap_dev_test = set(dev_patients) & set(test_patients)\n",
    "\n",
    "print(f\"\\n✓ Overlap train-dev: {len(overlap_train_dev)} pacientes (DEBE SER 0)\")\n",
    "print(f\"✓ Overlap train-test: {len(overlap_train_test)} pacientes (DEBE SER 0)\")\n",
    "print(f\"✓ Overlap dev-test: {len(overlap_dev_test)} pacientes (DEBE SER 0)\")\n",
    "\n",
    "assert len(overlap_train_dev) == 0, \"ERROR: Hay pacientes en train Y dev\"\n",
    "assert len(overlap_train_test) == 0, \"ERROR: Hay pacientes en train Y test\"\n",
    "assert len(overlap_dev_test) == 0, \"ERROR: Hay pacientes en dev Y test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335cd99",
   "metadata": {},
   "source": [
    "## 5. Obtener índices de casos (train/dev/test)\n",
    "\n",
    "Ahora convertimos pacientes → casos (consultas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64bb5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CASOS RESULTANTES\n",
      "============================================================\n",
      "Casos en train: 1849 (59.1%)\n",
      "Casos en dev:   641 (20.5%)\n",
      "Casos en test:  637 (20.4%)\n",
      "\n",
      "Distribución train:\n",
      "etiqueta\n",
      "depresion    1270\n",
      "ansiedad      579\n",
      "Name: count, dtype: int64\n",
      "Ratio A/D: 0.46\n",
      "\n",
      "Distribución dev:\n",
      "etiqueta\n",
      "depresion    456\n",
      "ansiedad     185\n",
      "Name: count, dtype: int64\n",
      "Ratio A/D: 0.41\n",
      "\n",
      "Distribución test:\n",
      "etiqueta\n",
      "depresion    476\n",
      "ansiedad     161\n",
      "Name: count, dtype: int64\n",
      "Ratio A/D: 0.34\n"
     ]
    }
   ],
   "source": [
    "# Filtrar casos por pacientes asignados\n",
    "train_mask = df[PATIENT_COL].isin(train_patients)\n",
    "dev_mask = df[PATIENT_COL].isin(dev_patients)\n",
    "test_mask = df[PATIENT_COL].isin(test_patients)\n",
    "\n",
    "train_idx = df[train_mask].index.tolist()\n",
    "dev_idx = df[dev_mask].index.tolist()\n",
    "test_idx = df[test_mask].index.tolist()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CASOS RESULTANTES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Casos en train: {len(train_idx)} ({len(train_idx)/n_cases*100:.1f}%)\")\n",
    "print(f\"Casos en dev:   {len(dev_idx)} ({len(dev_idx)/n_cases*100:.1f}%)\")\n",
    "print(f\"Casos en test:  {len(test_idx)} ({len(test_idx)/n_cases*100:.1f}%)\")\n",
    "\n",
    "# Distribución de clases en train/dev/test\n",
    "train_labels = df.loc[train_idx, LABEL_COL]\n",
    "dev_labels = df.loc[dev_idx, LABEL_COL]\n",
    "test_labels = df.loc[test_idx, LABEL_COL]\n",
    "\n",
    "print(f\"\\nDistribución train:\")\n",
    "print(train_labels.value_counts())\n",
    "print(f\"Ratio A/D: {train_labels.value_counts()['ansiedad'] / train_labels.value_counts()['depresion']:.2f}\")\n",
    "\n",
    "print(f\"\\nDistribución dev:\")\n",
    "print(dev_labels.value_counts())\n",
    "print(f\"Ratio A/D: {dev_labels.value_counts()['ansiedad'] / dev_labels.value_counts()['depresion']:.2f}\")\n",
    "\n",
    "print(f\"\\nDistribución test:\")\n",
    "print(test_labels.value_counts())\n",
    "print(f\"Ratio A/D: {test_labels.value_counts()['ansiedad'] / test_labels.value_counts()['depresion']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fbe24",
   "metadata": {},
   "source": [
    "## 6. Verificación: No data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a9079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICACIÓN DATA LEAKAGE\n",
      "============================================================\n",
      "Pacientes únicos en train: 54\n",
      "Pacientes únicos en dev:   18\n",
      "Pacientes únicos en test:  18\n",
      "\n",
      "Pacientes compartidos:\n",
      "  - train ∩ dev:  0\n",
      "  - train ∩ test: 0\n",
      "  - dev ∩ test:   0\n",
      "\n",
      "✅ VERIFICACIÓN EXITOSA: NO HAY DATA LEAKAGE\n"
     ]
    }
   ],
   "source": [
    "# Verificar que no hay pacientes compartidos\n",
    "train_patients_check = set(df.loc[train_idx, PATIENT_COL])\n",
    "dev_patients_check = set(df.loc[dev_idx, PATIENT_COL])\n",
    "test_patients_check = set(df.loc[test_idx, PATIENT_COL])\n",
    "\n",
    "overlap_train_dev = train_patients_check & dev_patients_check\n",
    "overlap_train_test = train_patients_check & test_patients_check\n",
    "overlap_dev_test = dev_patients_check & test_patients_check\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VERIFICACIÓN DATA LEAKAGE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pacientes únicos en train: {len(train_patients_check)}\")\n",
    "print(f\"Pacientes únicos en dev:   {len(dev_patients_check)}\")\n",
    "print(f\"Pacientes únicos en test:  {len(test_patients_check)}\")\n",
    "print(f\"\\nPacientes compartidos:\")\n",
    "print(f\"  - train ∩ dev:  {len(overlap_train_dev)}\")\n",
    "print(f\"  - train ∩ test: {len(overlap_train_test)}\")\n",
    "print(f\"  - dev ∩ test:   {len(overlap_dev_test)}\")\n",
    "\n",
    "if len(overlap_train_dev) == 0 and len(overlap_train_test) == 0 and len(overlap_dev_test) == 0:\n",
    "    print(\"\\n✅ VERIFICACIÓN EXITOSA: NO HAY DATA LEAKAGE\")\n",
    "else:\n",
    "    print(f\"\\n❌ ERROR: Hay pacientes compartidos entre conjuntos\")\n",
    "    if len(overlap_train_dev) > 0:\n",
    "        print(f\"Train-Dev overlap: {list(overlap_train_dev)[:5]}\")\n",
    "    if len(overlap_train_test) > 0:\n",
    "        print(f\"Train-Test overlap: {list(overlap_train_test)[:5]}\")\n",
    "    if len(overlap_dev_test) > 0:\n",
    "        print(f\"Dev-Test overlap: {list(overlap_dev_test)[:5]}\")\n",
    "    raise ValueError(\"DATA LEAKAGE DETECTADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349050d3",
   "metadata": {},
   "source": [
    "## 7. Guardar splits\n",
    "\n",
    "**IMPORTANTE:** Crear `row_id` único para cada caso (necesario para merge en baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "540f3175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ARCHIVOS GUARDADOS\n",
      "============================================================\n",
      "Ubicación: ../data/splits/\n",
      "\n",
      "1. dataset_base.csv\n",
      "   - 3127 casos\n",
      "   - Columnas: row_id, patient_id, texto, etiqueta\n",
      "\n",
      "2. train_indices.csv\n",
      "   - 1849 índices (de 54 pacientes)\n",
      "\n",
      "3. dev_indices.csv\n",
      "   - 641 índices (de 18 pacientes)\n",
      "\n",
      "4. test_indices.csv\n",
      "   - 637 índices (de 18 pacientes)\n"
     ]
    }
   ],
   "source": [
    "# Asignar row_id como índice original\n",
    "df['row_id'] = df.index\n",
    "\n",
    "# Preparar dataset base\n",
    "df_base = df[['row_id', PATIENT_COL, TEXT_COL, LABEL_COL]].copy()\n",
    "df_base.columns = ['row_id', 'patient_id', 'texto', 'etiqueta']\n",
    "\n",
    "# Normalizar etiquetas\n",
    "label_map = {'depresivo': 'depresion'}  # Mapeo si hay variantes\n",
    "df_base['etiqueta'] = df_base['etiqueta'].str.lower().map(lambda x: label_map.get(x, x))\n",
    "\n",
    "# Guardar archivos\n",
    "dataset_base_path = SPLITS_PATH / 'dataset_base.csv'\n",
    "train_indices_path = SPLITS_PATH / 'train_indices.csv'\n",
    "dev_indices_path = SPLITS_PATH / 'dev_indices.csv'\n",
    "test_indices_path = SPLITS_PATH / 'test_indices.csv'\n",
    "\n",
    "df_base.to_csv(dataset_base_path, index=False, encoding='utf-8')\n",
    "pd.DataFrame({'row_id': train_idx}).to_csv(train_indices_path, index=False)\n",
    "pd.DataFrame({'row_id': dev_idx}).to_csv(dev_indices_path, index=False)\n",
    "pd.DataFrame({'row_id': test_idx}).to_csv(test_indices_path, index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHIVOS GUARDADOS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Ubicación: {SPLITS_PATH}/\")\n",
    "print(f\"\\n1. dataset_base.csv\")\n",
    "print(f\"   - {len(df_base)} casos\")\n",
    "print(f\"   - Columnas: row_id, patient_id, texto, etiqueta\")\n",
    "print(f\"\\n2. train_indices.csv\")\n",
    "print(f\"   - {len(train_idx)} índices (de {len(train_patients)} pacientes)\")\n",
    "print(f\"\\n3. dev_indices.csv\")\n",
    "print(f\"   - {len(dev_idx)} índices (de {len(dev_patients)} pacientes)\")\n",
    "print(f\"\\n4. test_indices.csv\")\n",
    "print(f\"   - {len(test_idx)} índices (de {len(test_patients)} pacientes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f137dc",
   "metadata": {},
   "source": [
    "## 8. Reporte final y comparación\n",
    "\n",
    "Comparar distribución antes/después de split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d5a256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESUMEN: SPLIT POR PACIENTES (SIN LEAKAGE) - 3 CONJUNTOS\n",
      "============================================================\n",
      "\n",
      "DATASET COMPLETO:\n",
      "  - 90 pacientes\n",
      "  - 3127 casos (consultas)\n",
      "  - 34.7 casos/paciente promedio\n",
      "\n",
      "SPLIT REALIZADO (60/20/20):\n",
      "  - Train: 54 pacientes (1849 casos) - 59.1%\n",
      "  - Dev:   18 pacientes (641 casos) - 20.5%\n",
      "  - Test:  18 pacientes (637 casos) - 20.4%\n",
      "\n",
      "PROPÓSITO DE CADA CONJUNTO:\n",
      "  - Train: Análisis exploratorio, desarrollo de Concept_PY\n",
      "  - Dev:   Validación iterativa, ajuste de reglas (puede verse múltiples veces)\n",
      "  - Test:  Evaluación final CIEGA (solo una vez, comparación con baselines)\n",
      "\n",
      "VERIFICACIÓN:\n",
      "  - Pacientes compartidos train-dev: 0 (0 = correcto)\n",
      "  - Pacientes compartidos train-test: 0 (0 = correcto)\n",
      "  - Pacientes compartidos dev-test: 0 (0 = correcto)\n",
      "  - Estratificación por clase mayoritaria: ✓\n",
      "  - Random seed fijo: 42 (reproducible)\n",
      "\n",
      "CAMBIO vs SPLIT ANTERIOR (80/20):\n",
      "  - Antes: 2 conjuntos (train 80% / val 20%)\n",
      "  - Ahora: 3 conjuntos (train 60% / dev 20% / test 20%)\n",
      "  - Ventaja: Evita overfitting al desarrollar Concept_PY\n",
      "  - Dev set permite iterar sin contaminar test\n",
      "\n",
      "ARCHIVOS PARA BASELINES:\n",
      "  1. Cargar dataset_base.csv\n",
      "  2. Cargar train_indices.csv y dev_indices.csv\n",
      "  3. Filtrar usando row_id\n",
      "  4. Entrenar con train, evaluar con dev\n",
      "  5. Test se reserva para comparación final\n",
      "\n",
      "============================================================\n",
      "IMPORTANTE: RE-EJECUTAR TODOS LOS BASELINES con nuevos splits\n",
      "para actualizar métricas y mantener comparabilidad\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN: SPLIT POR PACIENTES (SIN LEAKAGE) - 3 CONJUNTOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDATASET COMPLETO:\")\n",
    "print(f\"  - {n_patients} pacientes\")\n",
    "print(f\"  - {n_cases} casos (consultas)\")\n",
    "print(f\"  - {avg_cases:.1f} casos/paciente promedio\")\n",
    "\n",
    "print(f\"\\nSPLIT REALIZADO (60/20/20):\")\n",
    "print(f\"  - Train: {len(train_patients)} pacientes ({len(train_idx)} casos) - {len(train_idx)/n_cases*100:.1f}%\")\n",
    "print(f\"  - Dev:   {len(dev_patients)} pacientes ({len(dev_idx)} casos) - {len(dev_idx)/n_cases*100:.1f}%\")\n",
    "print(f\"  - Test:  {len(test_patients)} pacientes ({len(test_idx)} casos) - {len(test_idx)/n_cases*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nPROPÓSITO DE CADA CONJUNTO:\")\n",
    "print(f\"  - Train: Análisis exploratorio, desarrollo de Concept_PY\")\n",
    "print(f\"  - Dev:   Validación iterativa, ajuste de reglas (puede verse múltiples veces)\")\n",
    "print(f\"  - Test:  Evaluación final CIEGA (solo una vez, comparación con baselines)\")\n",
    "\n",
    "print(f\"\\nVERIFICACIÓN:\")\n",
    "print(f\"  - Pacientes compartidos train-dev: {len(overlap_train_dev)} (0 = correcto)\")\n",
    "print(f\"  - Pacientes compartidos train-test: {len(overlap_train_test)} (0 = correcto)\")\n",
    "print(f\"  - Pacientes compartidos dev-test: {len(overlap_dev_test)} (0 = correcto)\")\n",
    "print(f\"  - Estratificación por clase mayoritaria: ✓\")\n",
    "print(f\"  - Random seed fijo: {RANDOM_STATE} (reproducible)\")\n",
    "\n",
    "print(f\"\\nCAMBIO vs SPLIT ANTERIOR (80/20):\")\n",
    "print(f\"  - Antes: 2 conjuntos (train 80% / val 20%)\")\n",
    "print(f\"  - Ahora: 3 conjuntos (train 60% / dev 20% / test 20%)\")\n",
    "print(f\"  - Ventaja: Evita overfitting al desarrollar Concept_PY\")\n",
    "print(f\"  - Dev set permite iterar sin contaminar test\")\n",
    "\n",
    "print(f\"\\nARCHIVOS PARA BASELINES:\")\n",
    "print(f\"  1. Cargar {dataset_base_path.name}\")\n",
    "print(f\"  2. Cargar {train_indices_path.name} y {dev_indices_path.name}\")\n",
    "print(f\"  3. Filtrar usando row_id\")\n",
    "print(f\"  4. Entrenar con train, evaluar con dev\")\n",
    "print(f\"  5. Test se reserva para comparación final\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPORTANTE: RE-EJECUTAR TODOS LOS BASELINES con nuevos splits\")\n",
    "print(\"para actualizar métricas y mantener comparabilidad\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
