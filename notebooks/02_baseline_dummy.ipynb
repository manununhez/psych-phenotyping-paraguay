{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15388f5",
   "metadata": {},
   "source": [
    "# 02_baseline_dummy â€” Sanity Check Baselines\n",
    "\n",
    "**Objetivo:** Implementar baselines triviales (majority class, random estratificado) para validar que los modelos ML capturan patrones reales y no overfitting.\n",
    "\n",
    "**Exportables:**\n",
    "- `data/dummy_majority_eval.csv` con mÃ©tricas del baseline majority\n",
    "- `data/dummy_stratified_eval.csv` con mÃ©tricas del baseline random estratificado\n",
    "- `data/02_baselines_con_dummy.csv` tabla consolidada con TODOS los modelos (incluye dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452649d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Usando utils_shared.py\n",
      " DATA_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data\n",
      " SPLITS_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Setup: Imports y configuraciÃ³n de paths\n",
    "# ===============================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# Importar utilidades compartidas\n",
    "try:\n",
    "    from utils_shared import setup_paths, load_splits\n",
    "    paths = setup_paths()\n",
    "    DATA_PATH = paths['DATA_PATH']\n",
    "    SPLITS_PATH = paths['SPLITS_PATH']\n",
    "    print(\"[OK] Usando utils_shared.py\")\n",
    "except ImportError:\n",
    "    print(\"[WARNING] No se encontrÃ³ utils_shared.py, usando configuraciÃ³n manual\")\n",
    "    BASE_PATH = Path.cwd()\n",
    "    if BASE_PATH.name == \"notebooks\":\n",
    "        BASE_PATH = BASE_PATH.parent\n",
    "    DATA_PATH = BASE_PATH / \"data\"\n",
    "    SPLITS_PATH = DATA_PATH / \"splits\"\n",
    "\n",
    "print(f\" DATA_PATH: {DATA_PATH}\")\n",
    "print(f\" SPLITS_PATH: {SPLITS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac6a8a",
   "metadata": {},
   "source": [
    "## 1) Cargar datos y splits\n",
    "\n",
    "Usamos los mismos splits pacientes que los otros baselines (patient-level, 0% leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85f1e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset base: 3155 casos\n",
      "Columnas: ['row_id', 'patient_id', 'texto', 'etiqueta']\n",
      "\n",
      "Train: 2509 casos\n",
      "Val: 646 casos\n",
      "\n",
      "DistribuciÃ³n train:\n",
      "depresion    1745\n",
      "ansiedad      764\n",
      "Name: count, dtype: int64\n",
      "\n",
      "DistribuciÃ³n val:\n",
      "depresion    485\n",
      "ansiedad     161\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset base\n",
    "df = pd.read_csv(SPLITS_PATH / \"dataset_base.csv\")\n",
    "print(f\"Dataset base: {len(df)} casos\")\n",
    "print(f\"Columnas: {df.columns.tolist()}\")\n",
    "\n",
    "# Cargar splits\n",
    "train_idx = pd.read_csv(SPLITS_PATH / \"train_indices.csv\")['row_id'].values\n",
    "val_idx = pd.read_csv(SPLITS_PATH / \"val_indices.csv\")['row_id'].values\n",
    "\n",
    "print(f\"\\nTrain: {len(train_idx)} casos\")\n",
    "print(f\"Val: {len(val_idx)} casos\")\n",
    "\n",
    "# Preparar X, y para train y val usando row_id como Ã­ndice\n",
    "df_indexed = df.set_index('row_id')\n",
    "X_train = df_indexed.loc[train_idx, 'texto'].values\n",
    "y_train = df_indexed.loc[train_idx, 'etiqueta'].values\n",
    "X_val = df_indexed.loc[val_idx, 'texto'].values\n",
    "y_val = df_indexed.loc[val_idx, 'etiqueta'].values\n",
    "\n",
    "print(f\"\\nDistribuciÃ³n train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nDistribuciÃ³n val:\")\n",
    "print(pd.Series(y_val).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1771302",
   "metadata": {},
   "source": [
    "## 2) Baseline 1: Majority Class\n",
    "\n",
    "Predice **siempre** la clase mayoritaria (DepresiÃ³n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073f019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUMMY BASELINE: MAJORITY CLASS\n",
      "============================================================\n",
      "Macro F1: 0.4288\n",
      "Macro Precision: 0.3754\n",
      "Macro Recall: 0.5000\n",
      "\n",
      "              precision    recall  f1-score     support\n",
      "ansiedad       0.000000  0.000000  0.000000  161.000000\n",
      "depresion      0.750774  1.000000  0.857648  485.000000\n",
      "accuracy       0.750774  0.750774  0.750774    0.750774\n",
      "macro avg      0.375387  0.500000  0.428824  646.000000\n",
      "weighted avg   0.563662  0.750774  0.643900  646.000000\n",
      "\n",
      "âœ“ Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_majority_eval.csv\n",
      "âœ“ Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_majority_classification_report.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Entrenar (solo aprende la clase mayoritaria)\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy_majority.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en validaciÃ³n\n",
    "y_pred_majority = dummy_majority.predict(X_val)\n",
    "\n",
    "# MÃ©tricas\n",
    "f1_majority = f1_score(y_val, y_pred_majority, average='macro')\n",
    "prec_majority = precision_score(y_val, y_pred_majority, average='macro')\n",
    "rec_majority = recall_score(y_val, y_pred_majority, average='macro')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DUMMY BASELINE: MAJORITY CLASS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Macro F1: {f1_majority:.4f}\")\n",
    "print(f\"Macro Precision: {prec_majority:.4f}\")\n",
    "print(f\"Macro Recall: {rec_majority:.4f}\")\n",
    "print()\n",
    "\n",
    "# Classification report completo\n",
    "report_majority = classification_report(y_val, y_pred_majority, output_dict=True)\n",
    "report_majority_df = pd.DataFrame(report_majority).transpose()\n",
    "print(report_majority_df)\n",
    "\n",
    "# Exportar mÃ©tricas macro\n",
    "eval_majority = pd.DataFrame([{\n",
    "    'modelo': 'dummy_majority',\n",
    "    'f1_macro': f1_majority,\n",
    "    'precision_macro': prec_majority,\n",
    "    'recall_macro': rec_majority,\n",
    "    'n_val': len(y_val)\n",
    "}])\n",
    "eval_majority.to_csv(DATA_PATH / 'dummy_majority_eval.csv', index=False)\n",
    "print(f\"\\nâœ“ Exportado: {DATA_PATH / 'dummy_majority_eval.csv'}\")\n",
    "\n",
    "# Exportar classification report\n",
    "report_majority_df.to_csv(DATA_PATH / 'dummy_majority_classification_report.csv')\n",
    "print(f\"âœ“ Exportado: {DATA_PATH / 'dummy_majority_classification_report.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a937eef",
   "metadata": {},
   "source": [
    "## 3) Baseline 2: Stratified Random\n",
    "\n",
    "Predice aleatoriamente respetando la distribuciÃ³n de clases del train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39862bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUMMY BASELINE: STRATIFIED RANDOM\n",
      "============================================================\n",
      "Macro F1: 0.4934\n",
      "Macro Precision: 0.4960\n",
      "Macro Recall: 0.4955\n",
      "\n",
      "              precision    recall  f1-score     support\n",
      "ansiedad       0.243781  0.304348  0.270718  161.000000\n",
      "depresion      0.748315  0.686598  0.716129  485.000000\n",
      "accuracy       0.591331  0.591331  0.591331    0.591331\n",
      "macro avg      0.496048  0.495473  0.493424  646.000000\n",
      "weighted avg   0.622572  0.591331  0.605121  646.000000\n",
      "\n",
      "âœ“ Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_stratified_eval.csv\n",
      "âœ“ Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_stratified_classification_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Entrenar (aprende solo la distribuciÃ³n de clases)\n",
    "dummy_stratified = DummyClassifier(strategy='stratified', random_state=42)\n",
    "dummy_stratified.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en validaciÃ³n\n",
    "y_pred_stratified = dummy_stratified.predict(X_val)\n",
    "\n",
    "# MÃ©tricas\n",
    "f1_stratified = f1_score(y_val, y_pred_stratified, average='macro')\n",
    "prec_stratified = precision_score(y_val, y_pred_stratified, average='macro')\n",
    "rec_stratified = recall_score(y_val, y_pred_stratified, average='macro')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DUMMY BASELINE: STRATIFIED RANDOM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Macro F1: {f1_stratified:.4f}\")\n",
    "print(f\"Macro Precision: {prec_stratified:.4f}\")\n",
    "print(f\"Macro Recall: {rec_stratified:.4f}\")\n",
    "print()\n",
    "\n",
    "# Classification report completo\n",
    "report_stratified = classification_report(y_val, y_pred_stratified, output_dict=True)\n",
    "report_stratified_df = pd.DataFrame(report_stratified).transpose()\n",
    "print(report_stratified_df)\n",
    "\n",
    "# Exportar mÃ©tricas macro\n",
    "eval_stratified = pd.DataFrame([{\n",
    "    'modelo': 'dummy_stratified',\n",
    "    'f1_macro': f1_stratified,\n",
    "    'precision_macro': prec_stratified,\n",
    "    'recall_macro': rec_stratified,\n",
    "    'n_val': len(y_val)\n",
    "}])\n",
    "eval_stratified.to_csv(DATA_PATH / 'dummy_stratified_eval.csv', index=False)\n",
    "print(f\"\\nâœ“ Exportado: {DATA_PATH / 'dummy_stratified_eval.csv'}\")\n",
    "\n",
    "# Exportar classification report\n",
    "report_stratified_df.to_csv(DATA_PATH / 'dummy_stratified_classification_report.csv')\n",
    "print(f\"âœ“ Exportado: {DATA_PATH / 'dummy_stratified_classification_report.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7771b",
   "metadata": {},
   "source": [
    "## 4) Exportar tabla consolidada\n",
    "\n",
    "Generamos la tabla `02_baselines_con_dummy.csv` que incluye TODOS los modelos (dummy + ML).\n",
    "\n",
    "**Para anÃ¡lisis completo de mejora, interpretaciÃ³n y visualizaciones:**\n",
    "â†’ Ver `notebooks/02_comparacion_resultados.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70eb5062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados modelos ML:\n",
      "     baseline  macro_f1  macro_precision  macro_recall      n\n",
      "0  rule_based  0.503060         0.516587      0.510629  646.0\n",
      "1       tfidf  0.755270         0.745770      0.768432  646.0\n",
      "2        beto  0.741577         0.736377      0.747711  646.0\n",
      "\n",
      "================================================================================\n",
      "TABLA CONSOLIDADA (todos los modelos)\n",
      "================================================================================\n",
      "          modelo  f1_macro  precision_macro  recall_macro  n_val\n",
      "           tfidf  0.755270         0.745770      0.768432  646.0\n",
      "            beto  0.741577         0.736377      0.747711  646.0\n",
      "      rule_based  0.503060         0.516587      0.510629  646.0\n",
      "dummy_stratified  0.493424         0.496048      0.495473  646.0\n",
      "  dummy_majority  0.428824         0.375387      0.500000  646.0\n",
      "\n",
      "âœ“ Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/02_baselines_con_dummy.csv\n",
      "\n",
      "ðŸ“Œ Para anÃ¡lisis completo, mejora vs dummy, y visualizaciones:\n",
      "   â†’ notebooks/02_comparacion_resultados.ipynb\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Exportar tabla consolidada con todos los modelos (incluye dummy)\n",
    "# ===============================================================\n",
    "\n",
    "# Cargar resultados de modelos ML\n",
    "comp_original = pd.read_csv(DATA_PATH / '02_baselines_comparacion.csv')\n",
    "print(\"Resultados modelos ML:\")\n",
    "print(comp_original)\n",
    "\n",
    "# Renombrar columnas de comp_original para coincidir\n",
    "comp_original_renamed = comp_original.rename(columns={\n",
    "    'baseline': 'modelo',\n",
    "    'macro_f1': 'f1_macro',\n",
    "    'macro_precision': 'precision_macro',\n",
    "    'macro_recall': 'recall_macro',\n",
    "    'n': 'n_val'\n",
    "})\n",
    "\n",
    "# Crear tabla consolidada con dummy baselines\n",
    "comp_con_dummy = pd.concat([\n",
    "    eval_majority[['modelo', 'f1_macro', 'precision_macro', 'recall_macro', 'n_val']],\n",
    "    eval_stratified[['modelo', 'f1_macro', 'precision_macro', 'recall_macro', 'n_val']],\n",
    "    comp_original_renamed[['modelo', 'f1_macro', 'precision_macro', 'recall_macro', 'n_val']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Ordenar por F1 (descendente)\n",
    "comp_con_dummy = comp_con_dummy.sort_values('f1_macro', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TABLA CONSOLIDADA (todos los modelos)\")\n",
    "print(\"=\" * 80)\n",
    "print(comp_con_dummy.to_string(index=False))\n",
    "\n",
    "# Exportar tabla consolidada\n",
    "out_csv = DATA_PATH / '02_baselines_con_dummy.csv'\n",
    "comp_con_dummy.to_csv(out_csv, index=False)\n",
    "print(f\"\\nâœ“ Exportado: {out_csv}\")\n",
    "print(f\"\\nðŸ“Œ Para anÃ¡lisis completo, mejora vs dummy, y visualizaciones:\")\n",
    "print(f\"   â†’ notebooks/02_comparacion_resultados.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
