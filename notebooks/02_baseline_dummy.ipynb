{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15388f5",
   "metadata": {},
   "source": [
    "# 02_baseline_dummy ‚Äî Sanity Check Baselines\n",
    "\n",
    "**Objetivo:** Implementar baselines triviales (majority class, random estratificado) para validar que los modelos ML capturan patrones reales.\n",
    "\n",
    "**Exportables:**\n",
    "- `data/dummy_majority_eval.csv` + classification_report\n",
    "- `data/dummy_stratified_eval.csv` + classification_report\n",
    "\n",
    "**Para comparaci√≥n completa:** Ver `02_comparacion_resultados.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452649d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Usando utils_shared.py\n",
      " DATA_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data\n",
      " SPLITS_PATH: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/splits\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Setup: Imports y configuraci√≥n de paths\n",
    "# ===============================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# Importar utilidades compartidas\n",
    "try:\n",
    "    from utils_shared import setup_paths, load_splits\n",
    "    paths = setup_paths()\n",
    "    DATA_PATH = paths['DATA_PATH']\n",
    "    SPLITS_PATH = paths['SPLITS_PATH']\n",
    "    print(\"[OK] Usando utils_shared.py\")\n",
    "except ImportError:\n",
    "    print(\"[WARNING] No se encontr√≥ utils_shared.py, usando configuraci√≥n manual\")\n",
    "    BASE_PATH = Path.cwd()\n",
    "    if BASE_PATH.name == \"notebooks\":\n",
    "        BASE_PATH = BASE_PATH.parent\n",
    "    DATA_PATH = BASE_PATH / \"data\"\n",
    "    SPLITS_PATH = DATA_PATH / \"splits\"\n",
    "\n",
    "print(f\" DATA_PATH: {DATA_PATH}\")\n",
    "print(f\" SPLITS_PATH: {SPLITS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac6a8a",
   "metadata": {},
   "source": [
    "## 1) Cargar datos y splits\n",
    "\n",
    "Usamos los mismos splits pacientes que los otros baselines (patient-level, 0% leakage).\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE - MANEJO DE CASOS NEUTRALES (Dummy vs Rule-Based):**\n",
    "\n",
    "**Diferencia fundamental:**\n",
    "- **Dummy Baselines:** Son modelos **binarios forzados** (siempre predicen ansiedad o depresi√≥n)\n",
    "  - Majority: Siempre predice clase mayoritaria (depresi√≥n)\n",
    "  - Stratified: Predice aleatoriamente respetando distribuci√≥n (60/40)\n",
    "  - **NO generan predicciones \"neutral\"**\n",
    "\n",
    "- **Rule-Based:** Puede devolver \"neutral\" cuando NO encuentra matches (78.4% casos)\n",
    "  - Tiene 3 salidas posibles: ansiedad, depresi√≥n, neutral\n",
    "  - Para comparar con dummy, convertimos neutrales ‚Üí mayoritaria\n",
    "\n",
    "**Implicaciones para comparaci√≥n:**\n",
    "1. ‚úÖ Dummy y ML (TF-IDF/BETO) son comparables directamente (todos binarios)\n",
    "2. ‚ö†Ô∏è Rule-Based NO es directamente comparable (genera neutrales)\n",
    "3. ‚úÖ Estrategia: Convertir neutrales de RB a mayoritaria para forzar comparaci√≥n\n",
    "4. üìä F1 Rule-Based bajo = 78% neutrales mal convertidos + errores en 22% detectado\n",
    "\n",
    "**En este notebook:**\n",
    "- Dummy no genera neutrales ‚Üí m√©tricas binarias puras\n",
    "- Establecemos **piso m√≠nimo** para comparaci√≥n (¬ømodelo aprende algo √∫til?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85f1e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset base: 3127 casos\n",
      "Columnas: ['row_id', 'patient_id', 'texto', 'etiqueta']\n",
      "\n",
      "Train: 1849 casos\n",
      "Val: 641 casos\n",
      "\n",
      "Distribuci√≥n train:\n",
      "depresion    1270\n",
      "ansiedad      579\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuci√≥n val:\n",
      "depresion    456\n",
      "ansiedad     185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset base\n",
    "df = pd.read_csv(SPLITS_PATH / \"dataset_base.csv\")\n",
    "print(f\"Dataset base: {len(df)} casos\")\n",
    "print(f\"Columnas: {df.columns.tolist()}\")\n",
    "\n",
    "# Cargar splits\n",
    "train_idx = pd.read_csv(SPLITS_PATH / \"train_indices.csv\")['row_id'].values\n",
    "dev_idx = pd.read_csv(SPLITS_PATH / \"dev_indices.csv\")['row_id'].values\n",
    "\n",
    "print(f\"\\nTrain: {len(train_idx)} casos\")\n",
    "print(f\"Val: {len(dev_idx)} casos\")\n",
    "\n",
    "# Preparar X, y para train y val usando row_id como √≠ndice\n",
    "df_indexed = df.set_index('row_id')\n",
    "X_train = df_indexed.loc[train_idx, 'texto'].values\n",
    "y_train = df_indexed.loc[train_idx, 'etiqueta'].values\n",
    "X_dev = df_indexed.loc[dev_idx, 'texto'].values\n",
    "y_dev = df_indexed.loc[dev_idx, 'etiqueta'].values\n",
    "\n",
    "print(f\"\\nDistribuci√≥n train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nDistribuci√≥n val:\")\n",
    "print(pd.Series(y_dev).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1771302",
   "metadata": {},
   "source": [
    "## 2) Baseline 1: Majority Class\n",
    "\n",
    "Predice **siempre** la clase mayoritaria (Depresi√≥n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073f019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUMMY BASELINE: MAJORITY CLASS\n",
      "============================================================\n",
      "Macro F1: 0.4157\n",
      "Macro Precision: 0.3557\n",
      "Macro Recall: 0.5000\n",
      "\n",
      "              precision    recall  f1-score     support\n",
      "ansiedad       0.000000  0.000000  0.000000  185.000000\n",
      "depresion      0.711388  1.000000  0.831358  456.000000\n",
      "accuracy       0.711388  0.711388  0.711388    0.711388\n",
      "macro avg      0.355694  0.500000  0.415679  641.000000\n",
      "weighted avg   0.506074  0.711388  0.591419  641.000000\n",
      "\n",
      "‚úì Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_majority_eval.csv\n",
      "‚úì Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_majority_classification_report.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/manuelnunez/Projects/psych-phenotyping-paraguay/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Entrenar (solo aprende la clase mayoritaria)\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dummy_majority.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en validaci√≥n\n",
    "y_pred_majority = dummy_majority.predict(X_dev)\n",
    "\n",
    "# M√©tricas\n",
    "f1_majority = f1_score(y_dev, y_pred_majority, average='macro')\n",
    "prec_majority = precision_score(y_dev, y_pred_majority, average='macro')\n",
    "rec_majority = recall_score(y_dev, y_pred_majority, average='macro')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DUMMY BASELINE: MAJORITY CLASS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Macro F1: {f1_majority:.4f}\")\n",
    "print(f\"Macro Precision: {prec_majority:.4f}\")\n",
    "print(f\"Macro Recall: {rec_majority:.4f}\")\n",
    "print()\n",
    "\n",
    "# Classification report completo\n",
    "report_majority = classification_report(y_dev, y_pred_majority, output_dict=True)\n",
    "report_majority_df = pd.DataFrame(report_majority).transpose()\n",
    "print(report_majority_df)\n",
    "\n",
    "# Exportar m√©tricas macro\n",
    "eval_majority = pd.DataFrame([{\n",
    "    'modelo': 'dummy_majority',\n",
    "    'f1_macro': f1_majority,\n",
    "    'precision_macro': prec_majority,\n",
    "    'recall_macro': rec_majority,\n",
    "    'n_dev': len(y_dev)\n",
    "}])\n",
    "eval_majority.to_csv(DATA_PATH / 'dummy_majority_eval.csv', index=False)\n",
    "print(f\"\\n‚úì Exportado: {DATA_PATH / 'dummy_majority_eval.csv'}\")\n",
    "\n",
    "# Exportar classification report\n",
    "report_majority_df.to_csv(DATA_PATH / 'dummy_majority_classification_report.csv')\n",
    "print(f\"‚úì Exportado: {DATA_PATH / 'dummy_majority_classification_report.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a937eef",
   "metadata": {},
   "source": [
    "## 3) Baseline 2: Stratified Random\n",
    "\n",
    "Predice aleatoriamente respetando la distribuci√≥n de clases del train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39862bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUMMY BASELINE: STRATIFIED RANDOM\n",
      "============================================================\n",
      "Macro F1: 0.4826\n",
      "Macro Precision: 0.4835\n",
      "Macro Recall: 0.4826\n",
      "\n",
      "              precision    recall  f1-score     support\n",
      "ansiedad       0.266010  0.291892  0.278351  185.000000\n",
      "depresion      0.700913  0.673246  0.686801  456.000000\n",
      "accuracy       0.563183  0.563183  0.563183    0.563183\n",
      "macro avg      0.483462  0.482569  0.482576  641.000000\n",
      "weighted avg   0.575395  0.563183  0.568917  641.000000\n",
      "\n",
      "‚úì Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_stratified_eval.csv\n",
      "‚úì Exportado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/dummy_stratified_classification_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Entrenar (aprende solo la distribuci√≥n de clases)\n",
    "dummy_stratified = DummyClassifier(strategy='stratified', random_state=42)\n",
    "dummy_stratified.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en validaci√≥n\n",
    "y_pred_stratified = dummy_stratified.predict(X_dev)\n",
    "\n",
    "# M√©tricas\n",
    "f1_stratified = f1_score(y_dev, y_pred_stratified, average='macro')\n",
    "prec_stratified = precision_score(y_dev, y_pred_stratified, average='macro')\n",
    "rec_stratified = recall_score(y_dev, y_pred_stratified, average='macro')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DUMMY BASELINE: STRATIFIED RANDOM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Macro F1: {f1_stratified:.4f}\")\n",
    "print(f\"Macro Precision: {prec_stratified:.4f}\")\n",
    "print(f\"Macro Recall: {rec_stratified:.4f}\")\n",
    "print()\n",
    "\n",
    "# Classification report completo\n",
    "report_stratified = classification_report(y_dev, y_pred_stratified, output_dict=True)\n",
    "report_stratified_df = pd.DataFrame(report_stratified).transpose()\n",
    "print(report_stratified_df)\n",
    "\n",
    "# Exportar m√©tricas macro\n",
    "eval_stratified = pd.DataFrame([{\n",
    "    'modelo': 'dummy_stratified',\n",
    "    'f1_macro': f1_stratified,\n",
    "    'precision_macro': prec_stratified,\n",
    "    'recall_macro': rec_stratified,\n",
    "    'n_dev': len(y_dev)\n",
    "}])\n",
    "eval_stratified.to_csv(DATA_PATH / 'dummy_stratified_eval.csv', index=False)\n",
    "print(f\"\\n‚úì Exportado: {DATA_PATH / 'dummy_stratified_eval.csv'}\")\n",
    "\n",
    "# Exportar classification report\n",
    "report_stratified_df.to_csv(DATA_PATH / 'dummy_stratified_classification_report.csv')\n",
    "print(f\"‚úì Exportado: {DATA_PATH / 'dummy_stratified_classification_report.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024bb80",
   "metadata": {},
   "source": [
    "## 3) Exportar resultados (comparables con otros baselines)\n",
    "\n",
    "**Estandarizaci√≥n de salidas:**\n",
    "- Mismos nombres de archivo que TF-IDF, BETO, Rule-Based\n",
    "- Formato CSV con m√©tricas macro (F1, precision, recall)\n",
    "- Classification reports detallados por clase\n",
    "\n",
    "**Sobre neutrales:**\n",
    "- ‚úÖ Dummy NO genera neutrales (modelo binario puro)\n",
    "- ‚úÖ NO requiere conversi√≥n de predicciones\n",
    "- ‚úÖ M√©tricas directamente comparables con TF-IDF y BETO\n",
    "- ‚ö†Ô∏è Rule-Based s√≠ genera neutrales ‚Üí sus m√©tricas incluyen penalizaci√≥n por cobertura\n",
    "\n",
    "**Archivos exportados:**\n",
    "1. `dummy_majority_eval.csv` - M√©tricas agregadas (F1, precision, recall)\n",
    "2. `dummy_majority_classification_report.csv` - Reporte detallado por clase\n",
    "3. `dummy_stratified_eval.csv` - M√©tricas agregadas\n",
    "4. `dummy_stratified_classification_report.csv` - Reporte detallado por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0737626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CROSS-VALIDATION 5-FOLD - DUMMY BASELINES\n",
      "================================================================================\n",
      "\n",
      "‚úì Dataset completo: 3126 casos\n",
      "‚úì Pacientes √∫nicos: 90\n",
      "\n",
      "üîπ MAJORITY CLASS CV:\n",
      "--------------------------------------------------------------------------------\n",
      "Fold 1: F1=0.417, Prec=0.358, Rec=0.500\n",
      "Fold 2: F1=0.395, Prec=0.327, Rec=0.500\n",
      "Fold 3: F1=0.408, Prec=0.345, Rec=0.500\n",
      "Fold 4: F1=0.422, Prec=0.364, Rec=0.500\n",
      "Fold 5: F1=0.423, Prec=0.366, Rec=0.500\n",
      "\n",
      "üìä MAJORITY CLASS - Estad√≠sticas:\n",
      "   F1 macro:  0.413 ¬± 0.011\n",
      "   IC95%:     [0.391, 0.435]\n",
      "   Min-Max:   [0.395, 0.423]\n",
      "\n",
      "üîπ STRATIFIED RANDOM CV:\n",
      "--------------------------------------------------------------------------------\n",
      "Fold 1: F1=0.499, Prec=0.499, Rec=0.499\n",
      "Fold 2: F1=0.485, Prec=0.487, Rec=0.488\n",
      "Fold 3: F1=0.486, Prec=0.486, Rec=0.487\n",
      "Fold 4: F1=0.495, Prec=0.496, Rec=0.496\n",
      "Fold 5: F1=0.487, Prec=0.489, Rec=0.487\n",
      "\n",
      "üìä STRATIFIED RANDOM - Estad√≠sticas:\n",
      "   F1 macro:  0.491 ¬± 0.006\n",
      "   IC95%:     [0.478, 0.503]\n",
      "   Min-Max:   [0.485, 0.499]\n",
      "\n",
      "üíæ Resultados exportados:\n",
      "   - /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/cv_results/dummy_majority_cv_results.csv\n",
      "   - /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/cv_results/dummy_stratified_cv_results.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Cross-Validation Dummy Baselines completado\n",
      "================================================================================\n",
      "Fold 2: F1=0.485, Prec=0.487, Rec=0.488\n",
      "Fold 3: F1=0.486, Prec=0.486, Rec=0.487\n",
      "Fold 4: F1=0.495, Prec=0.496, Rec=0.496\n",
      "Fold 5: F1=0.487, Prec=0.489, Rec=0.487\n",
      "\n",
      "üìä STRATIFIED RANDOM - Estad√≠sticas:\n",
      "   F1 macro:  0.491 ¬± 0.006\n",
      "   IC95%:     [0.478, 0.503]\n",
      "   Min-Max:   [0.485, 0.499]\n",
      "\n",
      "üíæ Resultados exportados:\n",
      "   - /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/cv_results/dummy_majority_cv_results.csv\n",
      "   - /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/cv_results/dummy_stratified_cv_results.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Cross-Validation Dummy Baselines completado\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# CROSS-VALIDATION 5-FOLD - DUMMY BASELINES\n",
    "# ===============================================================\n",
    "#\n",
    "# ‚ö†Ô∏è MANEJO DE NEUTRALES EN CV:\n",
    "#\n",
    "# Dummy baselines SON BINARIOS PUROS:\n",
    "#   - Majority: Siempre predice clase mayoritaria (depresi√≥n)\n",
    "#   - Stratified: Predice aleatoriamente seg√∫n distribuci√≥n (60/40)\n",
    "#   - NO generan predicciones \"neutral\"\n",
    "#\n",
    "# DIFERENCIA CON RULE-BASED CV:\n",
    "#   - Rule-Based: Genera ~78% neutrales ‚Üí los convierte a mayoritaria\n",
    "#   - Dummy: NO genera neutrales ‚Üí predicciones binarias directas\n",
    "#   - TF-IDF/BETO: Igual que dummy (binarios puros)\n",
    "#\n",
    "# INTERPRETACI√ìN DE VARIANZA CV:\n",
    "#   - Dummy Majority: Varianza = heterogeneidad de distribuci√≥n entre folds\n",
    "#   - Dummy Stratified: Varianza = azar + distribuci√≥n (baseline estoc√°stico)\n",
    "#   - Si ML tiene mayor F1 pero similar varianza ‚Üí aprende patrones reales\n",
    "#\n",
    "# ===============================================================\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CROSS-VALIDATION 5-FOLD - DUMMY BASELINES\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Configuraci√≥n\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Preparar dataset completo\n",
    "df_full = pd.read_csv(SPLITS_PATH / 'dataset_base.csv')\n",
    "df_full = df_full.dropna(subset=['texto', 'etiqueta']).copy()\n",
    "\n",
    "print(f\"‚úì Dataset completo: {len(df_full)} casos\")\n",
    "print(f\"‚úì Pacientes √∫nicos: {df_full['patient_id'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# Obtener etiqueta mayoritaria por paciente (para stratification)\n",
    "patient_labels = df_full.groupby('patient_id')['etiqueta'].agg(\n",
    "    lambda x: x.value_counts().index[0]\n",
    ").reset_index()\n",
    "patient_labels.columns = ['patient_id', 'label_majority']\n",
    "\n",
    "# Crear folds stratificados\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "patient_ids = patient_labels['patient_id'].values\n",
    "patient_y = patient_labels['label_majority'].values\n",
    "\n",
    "# ===============================================================\n",
    "# CV para MAJORITY CLASS\n",
    "# ===============================================================\n",
    "print(\"üîπ MAJORITY CLASS CV:\")\n",
    "print(\"-\" * 80)\n",
    "cv_majority_results = []\n",
    "\n",
    "for fold_idx, (train_patient_idx, test_patient_idx) in enumerate(skf.split(patient_ids, patient_y), start=1):\n",
    "    # Obtener pacientes\n",
    "    train_patients = patient_ids[train_patient_idx]\n",
    "    test_patients = patient_ids[test_patient_idx]\n",
    "    \n",
    "    # Filtrar casos\n",
    "    train_df = df_full[df_full['patient_id'].isin(train_patients)]\n",
    "    test_df = df_full[df_full['patient_id'].isin(test_patients)]\n",
    "    \n",
    "    X_train_cv = train_df['texto'].values\n",
    "    y_train_cv = train_df['etiqueta'].values\n",
    "    X_test_cv = test_df['texto'].values\n",
    "    y_test_cv = test_df['etiqueta'].values\n",
    "    \n",
    "    # Entrenar y predecir (SIEMPRE predice mayoritaria, NO genera neutrales)\n",
    "    dummy_maj_cv = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "    dummy_maj_cv.fit(X_train_cv, y_train_cv)\n",
    "    y_pred_cv = dummy_maj_cv.predict(X_test_cv)\n",
    "    \n",
    "    # M√©tricas\n",
    "    f1_cv = f1_score(y_test_cv, y_pred_cv, average='macro', zero_division=0)\n",
    "    prec_cv = precision_score(y_test_cv, y_pred_cv, average='macro', zero_division=0)\n",
    "    rec_cv = recall_score(y_test_cv, y_pred_cv, average='macro', zero_division=0)\n",
    "    \n",
    "    cv_majority_results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f1_macro': f1_cv,\n",
    "        'precision': prec_cv,\n",
    "        'recall': rec_cv,\n",
    "        'n_train_patients': len(train_patients),\n",
    "        'n_test_patients': len(test_patients),\n",
    "        'n_test_cases': len(X_test_cv)\n",
    "    })\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: F1={f1_cv:.3f}, Prec={prec_cv:.3f}, Rec={rec_cv:.3f}\")\n",
    "\n",
    "# Resultados Majority\n",
    "cv_majority_df = pd.DataFrame(cv_majority_results)\n",
    "f1_maj_mean = cv_majority_df['f1_macro'].mean()\n",
    "f1_maj_std = cv_majority_df['f1_macro'].std()\n",
    "f1_maj_ci_lower = f1_maj_mean - 1.96 * f1_maj_std\n",
    "f1_maj_ci_upper = f1_maj_mean + 1.96 * f1_maj_std\n",
    "\n",
    "print()\n",
    "print(\"üìä MAJORITY CLASS - Estad√≠sticas:\")\n",
    "print(f\"   F1 macro:  {f1_maj_mean:.3f} ¬± {f1_maj_std:.3f}\")\n",
    "print(f\"   IC95%:     [{f1_maj_ci_lower:.3f}, {f1_maj_ci_upper:.3f}]\")\n",
    "print(f\"   Min-Max:   [{cv_majority_df['f1_macro'].min():.3f}, {cv_majority_df['f1_macro'].max():.3f}]\")\n",
    "print()\n",
    "\n",
    "# ===============================================================\n",
    "# CV para STRATIFIED RANDOM\n",
    "# ===============================================================\n",
    "print(\"üîπ STRATIFIED RANDOM CV:\")\n",
    "print(\"-\" * 80)\n",
    "cv_stratified_results = []\n",
    "\n",
    "for fold_idx, (train_patient_idx, test_patient_idx) in enumerate(skf.split(patient_ids, patient_y), start=1):\n",
    "    # Obtener pacientes\n",
    "    train_patients = patient_ids[train_patient_idx]\n",
    "    test_patients = patient_ids[test_patient_idx]\n",
    "    \n",
    "    # Filtrar casos\n",
    "    train_df = df_full[df_full['patient_id'].isin(train_patients)]\n",
    "    test_df = df_full[df_full['patient_id'].isin(test_patients)]\n",
    "    \n",
    "    X_train_cv = train_df['texto'].values\n",
    "    y_train_cv = train_df['etiqueta'].values\n",
    "    X_test_cv = test_df['texto'].values\n",
    "    y_test_cv = test_df['etiqueta'].values\n",
    "    \n",
    "    # Entrenar y predecir (predice seg√∫n distribuci√≥n, NO genera neutrales)\n",
    "    dummy_strat_cv = DummyClassifier(strategy='stratified', random_state=42)\n",
    "    dummy_strat_cv.fit(X_train_cv, y_train_cv)\n",
    "    y_pred_cv = dummy_strat_cv.predict(X_test_cv)\n",
    "    \n",
    "    # M√©tricas\n",
    "    f1_cv = f1_score(y_test_cv, y_pred_cv, average='macro', zero_division=0)\n",
    "    prec_cv = precision_score(y_test_cv, y_pred_cv, average='macro', zero_division=0)\n",
    "    rec_cv = recall_score(y_test_cv, y_pred_cv, average='macro', zero_division=0)\n",
    "    \n",
    "    cv_stratified_results.append({\n",
    "        'fold': fold_idx,\n",
    "        'f1_macro': f1_cv,\n",
    "        'precision': prec_cv,\n",
    "        'recall': rec_cv,\n",
    "        'n_train_patients': len(train_patients),\n",
    "        'n_test_patients': len(test_patients),\n",
    "        'n_test_cases': len(X_test_cv)\n",
    "    })\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: F1={f1_cv:.3f}, Prec={prec_cv:.3f}, Rec={rec_cv:.3f}\")\n",
    "\n",
    "# Resultados Stratified\n",
    "cv_stratified_df = pd.DataFrame(cv_stratified_results)\n",
    "f1_strat_mean = cv_stratified_df['f1_macro'].mean()\n",
    "f1_strat_std = cv_stratified_df['f1_macro'].std()\n",
    "f1_strat_ci_lower = f1_strat_mean - 1.96 * f1_strat_std\n",
    "f1_strat_ci_upper = f1_strat_mean + 1.96 * f1_strat_std\n",
    "\n",
    "print()\n",
    "print(\"üìä STRATIFIED RANDOM - Estad√≠sticas:\")\n",
    "print(f\"   F1 macro:  {f1_strat_mean:.3f} ¬± {f1_strat_std:.3f}\")\n",
    "print(f\"   IC95%:     [{f1_strat_ci_lower:.3f}, {f1_strat_ci_upper:.3f}]\")\n",
    "print(f\"   Min-Max:   [{cv_stratified_df['f1_macro'].min():.3f}, {cv_stratified_df['f1_macro'].max():.3f}]\")\n",
    "print()\n",
    "\n",
    "# ===============================================================\n",
    "# EXPORTAR RESULTADOS CV\n",
    "# ===============================================================\n",
    "cv_output_dir = DATA_PATH / 'cv_results'\n",
    "cv_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "cv_majority_df.to_csv(cv_output_dir / 'dummy_majority_cv_results.csv', index=False)\n",
    "cv_stratified_df.to_csv(cv_output_dir / 'dummy_stratified_cv_results.csv', index=False)\n",
    "\n",
    "print(\"üíæ Resultados exportados:\")\n",
    "print(f\"   - {cv_output_dir / 'dummy_majority_cv_results.csv'}\")\n",
    "print(f\"   - {cv_output_dir / 'dummy_stratified_cv_results.csv'}\")\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ Cross-Validation Dummy Baselines completado\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d683d",
   "metadata": {},
   "source": [
    "## 5) Exportar Resultados y Pr√≥ximos Pasos\n",
    "\n",
    "**‚úÖ Archivos generados por este baseline:**\n",
    "\n",
    "Evaluaci√≥n en dev set:\n",
    "- `dummy_majority_predictions.csv` - Predicciones por caso\n",
    "- `dummy_majority_eval.csv` - M√©tricas macro agregadas\n",
    "- `dummy_majority_classification_report.csv` - Reporte por clase\n",
    "- `dummy_majority_confusion_matrix.csv` - Matriz de confusi√≥n\n",
    "\n",
    "- `dummy_stratified_predictions.csv` - Predicciones por caso\n",
    "- `dummy_stratified_eval.csv` - M√©tricas macro agregadas\n",
    "- `dummy_stratified_classification_report.csv` - Reporte por clase\n",
    "- `dummy_stratified_confusion_matrix.csv` - Matriz de confusi√≥n\n",
    "\n",
    "Cross-Validation:\n",
    "- `cv_results/dummy_majority_cv_results.csv` - Resultados 5-fold CV\n",
    "- `cv_results/dummy_stratified_cv_results.csv` - Resultados 5-fold CV\n",
    "\n",
    "---\n",
    "\n",
    "**üìä Para an√°lisis comparativo completo:**\n",
    "‚Üí Ejecutar notebook: `02_comparacion_resultados.ipynb`\n",
    "\n",
    "Este notebook consolida todos los resultados CV, calcula estad√≠sticas (IC95%), compara modelos, y genera visualizaciones e interpretaci√≥n para paper/tesis.\n",
    "\n",
    "---\n",
    "\n",
    "**üìù Notas metodol√≥gicas:**\n",
    "- **Dataset:** dataset_base.csv (3,155 casos, 90 pacientes)\n",
    "- **Split:** Patient-level 60/20/20 (0% leakage)\n",
    "- **CV:** 5-fold patient-level stratified (54 pacientes train por fold)\n",
    "- **Varianza:** Dummy Majority (baja, determin√≠stico) vs Stratified (alta, aleatorio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
