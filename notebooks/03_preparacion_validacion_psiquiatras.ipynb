{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Preparación de Validación con Psiquiatras (Post-Denoising)\n",
        "\n",
        "**Objetivo:** Generar un set de casos para validar decisiones críticas del pipeline, específicamente el proceso de **Denoising** y la calidad de las etiquetas.\n",
        "\n",
        "**Cambio de Estrategia:**\n",
        "Anteriormente nos enfocábamos en detectar \"ruido administrativo\". Ahora que hemos implementado un **Denoising Rule-Based** (Notebook 03), el objetivo es validar si este proceso es correcto:\n",
        "1. **Validar Exclusiones (Falsos Negativos del Denoising):** ¿Estamos eliminando casos que SÍ tienen información clínica relevante?\n",
        "2. **Validar Inclusiones (Falsos Positivos del Denoising):** ¿Estamos incluyendo casos que siguen siendo ruido?\n",
        "3. **Validar Negaciones:** Decidimos incluir síntomas negados (ej: \"niega ansiedad\"). ¿Están de acuerdo los psiquiatras?\n",
        "4. **Validar Vocabulario:** Identificar términos paraguayos en los casos que el sistema no detectó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Paths configurados.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Importar utilidades compartidas\n",
        "current_dir = Path.cwd()\n",
        "if current_dir.name == \"notebooks\":\n",
        "    sys.path.append(str(current_dir.parent))\n",
        "else:\n",
        "    sys.path.append(str(current_dir))\n",
        "\n",
        "try:\n",
        "    from notebooks.utils_shared import setup_paths\n",
        "except ImportError:\n",
        "    sys.path.append(str(current_dir))\n",
        "    from utils_shared import setup_paths\n",
        "\n",
        "paths = setup_paths()\n",
        "DATA_PATH = paths['DATA_PATH']\n",
        "SPLITS_PATH = paths['SPLITS_PATH']\n",
        "\n",
        "print(f\"[OK] Paths configurados.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cargar Datos: Original vs Denoised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total casos: 3131\n",
            "Casos MANTENIDOS (Clinical Signal): 993 (31.7%)\n",
            "Casos EXCLUIDOS (Noise/No Signal): 2138 (68.3%)\n"
          ]
        }
      ],
      "source": [
        "# Cargar dataset base (todos los casos)\n",
        "df_base = pd.read_csv(SPLITS_PATH / 'dataset_base.csv')\n",
        "\n",
        "# Cargar dataset denoised (solo los que pasaron el filtro)\n",
        "try:\n",
        "    df_denoised = pd.read_csv(SPLITS_PATH / 'train_denoised.csv')\n",
        "    denoised_ids = set(df_denoised['row_id'])\n",
        "except FileNotFoundError:\n",
        "    print(\"[ERROR] No se encontró train_denoised.csv. Ejecuta 03_rule_based_denoising.ipynb primero.\")\n",
        "    raise\n",
        "\n",
        "# Identificar excluidos\n",
        "df_base['is_kept'] = df_base['row_id'].isin(denoised_ids)\n",
        "df_excluded = df_base[~df_base['is_kept']].copy()\n",
        "df_included = df_base[df_base['is_kept']].copy()\n",
        "\n",
        "print(f\"Total casos: {len(df_base)}\")\n",
        "print(f\"Casos MANTENIDOS (Clinical Signal): {len(df_included)} ({len(df_included)/len(df_base):.1%})\")\n",
        "print(f\"Casos EXCLUIDOS (Noise/No Signal): {len(df_excluded)} ({len(df_excluded)/len(df_base):.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Selección de Casos para Validación\n",
        "\n",
        "Seleccionaremos 25 casos distribuidos estratégicamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seleccionados 22 casos para validación.\n",
            "Grupo\n",
            "Excluido_Sospechoso    10\n",
            "Inclusion_Negacion      8\n",
            "Inclusion_Corta         4\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/25/fy01l91x3gj63g090ghxj7000000gn/T/ipykernel_44429/3827656830.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  mask_negacion = df_included['texto'].str.lower().str.contains(r'\\b(no|niega|sin)\\b', regex=True, na=False)\n"
          ]
        }
      ],
      "source": [
        "casos_seleccionados = []\n",
        "\n",
        "# --- GRUPO 1: Excluidos \"Sospechosos\" (Posibles Falsos Negativos) ---\n",
        "# Buscamos casos excluidos que sean largos (>50 chars). Si son largos y se borraron,\n",
        "# quizás contienen vocabulario paraguayo no detectado.\n",
        "excluidos_largos = df_excluded[df_excluded['texto'].str.len() > 50]\n",
        "if not excluidos_largos.empty:\n",
        "    sample_excluidos = excluidos_largos.sample(min(10, len(excluidos_largos)), random_state=42)\n",
        "    sample_excluidos['Grupo'] = 'Excluido_Sospechoso'\n",
        "    sample_excluidos['Motivo'] = 'Texto largo pero borrado por denoising. ¿Contiene síntomas no detectados?'\n",
        "    casos_seleccionados.append(sample_excluidos)\n",
        "\n",
        "# --- GRUPO 2: Inclusiones con Negación (Validar Criterio) ---\n",
        "# Buscamos casos mantenidos que contengan \"no \" o \"niega\".\n",
        "# Queremos confirmar si los psiquiatras consideran esto evidencia clínica.\n",
        "mask_negacion = df_included['texto'].str.lower().str.contains(r'\\b(no|niega|sin)\\b', regex=True, na=False)\n",
        "incluidos_negados = df_included[mask_negacion]\n",
        "if not incluidos_negados.empty:\n",
        "    sample_negados = incluidos_negados.sample(min(8, len(incluidos_negados)), random_state=42)\n",
        "    sample_negados['Grupo'] = 'Inclusion_Negacion'\n",
        "    sample_negados['Motivo'] = 'Contiene negaciones. ¿Es síntoma (falta insight) o ausencia real?'\n",
        "    casos_seleccionados.append(sample_negados)\n",
        "\n",
        "# --- GRUPO 3: Casos Cortos Mantenidos (Posibles Falsos Positivos) ---\n",
        "# Casos cortos que pasaron el filtro. ¿Son realmente útiles?\n",
        "incluidos_cortos = df_included[df_included['texto'].str.len() < 100]\n",
        "if not incluidos_cortos.empty:\n",
        "    sample_cortos = incluidos_cortos.sample(min(7, len(incluidos_cortos)), random_state=42)\n",
        "    sample_cortos['Grupo'] = 'Inclusion_Corta'\n",
        "    sample_cortos['Motivo'] = 'Texto corto mantenido. ¿Es suficiente evidencia?'\n",
        "    casos_seleccionados.append(sample_cortos)\n",
        "\n",
        "# Unificar\n",
        "df_validacion = pd.concat(casos_seleccionados).head(25)\n",
        "\n",
        "# Preparar columnas para el Excel\n",
        "cols_export = ['row_id', 'Grupo', 'etiqueta', 'texto', 'Motivo']\n",
        "df_export = df_validacion[cols_export].copy()\n",
        "df_export['Validacion_Psiquiatra'] = ''  # Espacio para que escriban\n",
        "df_export['Comentarios'] = ''\n",
        "\n",
        "print(f\"Seleccionados {len(df_export)} casos para validación.\")\n",
        "print(df_export['Grupo'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exportar a Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Excel generado: /Users/manuelnunez/Projects/psych-phenotyping-paraguay/data/VALIDACION_PSIQUIATRAS_POST_DENOISING.xlsx\n"
          ]
        }
      ],
      "source": [
        "output_file = DATA_PATH / \"VALIDACION_PSIQUIATRAS_POST_DENOISING.xlsx\"\n",
        "try:\n",
        "    df_export.to_excel(output_file, index=False)\n",
        "    print(f\"[OK] Excel generado: {output_file}\")\n",
        "except ImportError:\n",
        "    print(\"[ERROR] Falta openpyxl. Instalando...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"openpyxl\"])\n",
        "    df_export.to_excel(output_file, index=False)\n",
        "    print(f\"[OK] Excel generado: {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
